{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRC3jy_AR7qF",
        "outputId": "d68b66ff-9c82-4b08-a0a1-6d3a06eb0f53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.21.0 typeguard-2.13.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from tensorflow_addons.layers import StochasticDepth\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "\n",
        "\n",
        "import ssl\n",
        "\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preparazione iperparametri di addestramento\n"
      ],
      "metadata": {
        "id": "GuVJ_nY5n6U7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "projection_dim = 128\n",
        "num_heads = 2\n",
        "transformer_units = [projection_dim, projection_dim, projection_dim]\n",
        "transformer_layers = len(transformer_units)\n",
        "dropout = 0.25\n",
        "\n",
        "learning_rate = 5e-3\n",
        "weight_decay = 1e-5\n",
        "batch_size = 256\n",
        "num_epochs = 500\n",
        "image_size = 32\n"
      ],
      "metadata": {
        "id": "DNp707uJSEq9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importazione del dataset"
      ],
      "metadata": {
        "id": "QxAMqju9oDj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 100\n",
        "input_shape = (32, 32, 3)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMtNnQQ3S_Ql",
        "outputId": "f4f95c6d-9538-484f-e3c0-7ad8fe5eb244"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 4s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 100)\n",
            "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creo la classe CCTTokenaizer che mi permette tramite una rete convolutiva di estrarre le features dalle immagini e un positional embedding che terra traccia della posizione delle features sulla quale poi il modello effettuera le previsioni"
      ],
      "metadata": {
        "id": "npHuBzxYoKWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CCTTokenizer(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        kernel_size = 3,\n",
        "        stride = 1,\n",
        "        padding = 1,\n",
        "        pooling_kernel_size = 3,\n",
        "        pooling_stride = 2,\n",
        "        num_output_channels = [64, 128],\n",
        "        **kwargs\n",
        "    ):\n",
        "        super(CCTTokenizer, self).__init__(**kwargs)\n",
        "        # sotto-rete convolutiva che fa da tokenizzatore\n",
        "        self.conv_model = tf.keras.Sequential()\n",
        "        for i in range(len(num_output_channels)):\n",
        "            self.conv_model.add(tf.keras.layers.Conv2D(num_output_channels[i], kernel_size, stride, padding = \"valid\", activation = \"swish\"))\n",
        "            self.conv_model.add(tf.keras.layers.ZeroPadding2D(padding))\n",
        "            self.conv_model.add(tf.keras.layers.MaxPool2D(pooling_kernel_size, pooling_stride, \"same\"))\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, images):\n",
        "        outputs = self.conv_model(images)\n",
        "        # cambio di dimensionalità per formare sequenze di feature estratte\n",
        "        reshaped = tf.reshape(outputs, (-1, tf.shape(outputs)[1] * tf.shape(outputs)[2], tf.shape(outputs)[3]),\n",
        "                             )\n",
        "        return reshaped\n",
        "\n",
        "    def positional_embedding(self, image_size):\n",
        "        # calcolo del numero di sequenze e inizializzazione del\n",
        "        # layer di Embedding che verrà utilizzato successivamente\n",
        "        # per il calcolo degli embedding posizionali\n",
        "        dummy_inputs = tf.zeros((1, image_size, image_size, 3))\n",
        "        dummy_outputs = self.call(dummy_inputs)\n",
        "        sequence_length = tf.shape(dummy_outputs)[1]\n",
        "        projection_dim = tf.shape(dummy_outputs)[-1]\n",
        "\n",
        "        embed_layer = tf.keras.layers.Embedding(input_dim = sequence_length, output_dim = projection_dim)\n",
        "        return embed_layer, sequence_length\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uEGJ_kZ5TEbq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rete neurale feedforward multi-layer (MLP), anche conosciuta come rete fully connected"
      ],
      "metadata": {
        "id": "fC1mRQ5foyt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = tf.keras.layers.Dense(units, activation=\"swish\")(x)\n",
        "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "4JNhN_gbTHeG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data agumentation per aumentare le dimensionalita del dataset"
      ],
      "metadata": {
        "id": "juXgsiEdo4pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.models.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Rescaling(scale=1.0 / 255),\n",
        "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "        tf.keras.layers.RandomZoom(0.1),\n",
        "        tf.keras.layers.RandomRotation(0.1)\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")"
      ],
      "metadata": {
        "id": "xpaSo-tyTKGq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Architettura Compact convolutional trasformer"
      ],
      "metadata": {
        "id": "E5tYGdDppAec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cct_model(\n",
        "    image_size = image_size,\n",
        "    input_shape=input_shape,\n",
        "    num_heads=num_heads,\n",
        "    projection_dim=projection_dim,\n",
        "    transformer_units=transformer_units,\n",
        "):\n",
        "    inputs = tf.keras.layers.Input(input_shape)\n",
        "\n",
        "    augmented = data_augmentation(inputs)\n",
        "\n",
        "    # codifica delle \"patches\":\n",
        "    # nei CCT non sono pezzi dell'immagine (in pxl) di input\n",
        "    # ma sequenze di feature estratte\n",
        "    cct_tokenizer = CCTTokenizer()\n",
        "    encoded_patches = cct_tokenizer(augmented)\n",
        "\n",
        "    # impostazione del positional embedding\n",
        "    # sommo il positional Embedding all'uscita del tokenizer\n",
        "    # in modo che le feature-map abbiano al loro interno anche la posizione\n",
        "    pos_embed, seq_length = cct_tokenizer.positional_embedding(image_size)\n",
        "    positions = tf.range(start = 0, limit = seq_length, delta=1)\n",
        "    position_embeddings = pos_embed(positions)\n",
        "    encoded_patches += position_embeddings\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(transformer_layers):\n",
        "        # Layer Normalization\n",
        "        x1 = tf.keras.layers.LayerNormalization(epsilon = 1e-5)(encoded_patches)\n",
        "        # MultiHeadAttention\n",
        "        attention_output = tf.keras.layers.MultiHeadAttention(num_heads = num_heads, key_dim = 256, dropout=0.1)(x1, x1)\n",
        "        # Skip Connection\n",
        "        attention_output = tf.keras.layers.Dropout(dropout)(attention_output)\n",
        "        x2 = StochasticDepth(survival_probability= 0.25)([encoded_patches, attention_output])\n",
        "        # Layer normalization\n",
        "        x3 = tf.keras.layers.LayerNormalization(epsilon = 1e-5)(x2)\n",
        "        # MLP\n",
        "        x3 = mlp(x3, hidden_units = transformer_units, dropout_rate = dropout)\n",
        "        # Skip Connection\n",
        "        encoded_patches2 = StochasticDepth(survival_probability=0.25)([x2, x3])\n",
        "\n",
        "\n",
        "    encoded_patches3 = StochasticDepth(survival_probability=0.25)([encoded_patches2, encoded_patches2])\n",
        "    # Pooling sulle sequenze\n",
        "    representation = tf.keras.layers.LayerNormalization(epsilon= 1e-5)(encoded_patches3)\n",
        "    # \"representation\" ha dimensioni (batch, 64, 128) -> una sequenza di 64 elementi descritti su 128 dimensioni\n",
        "    attention_weights = tf.nn.softmax(tf.keras.layers.Dense(1)(representation), axis=1)\n",
        "    weighted_representation = tf.matmul(attention_weights, representation, transpose_a=True)\n",
        "    # -> (1, 64) * (64, 128) => (1, 128)\n",
        "\n",
        "    weighted_representation = tf.squeeze(weighted_representation, -2)\n",
        "    # squeeze((batch, 1, 128), -2) -> (batch, 128)\n",
        "\n",
        "    # output (classificazione finale)\n",
        "    logits = tf.keras.layers.Dense(num_classes)(weighted_representation)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=logits)\n",
        "    model.summary()\n",
        "\n",
        "    tf.keras.utils.plot_model(model, to_file='model.png', expand_nested=True, show_shapes=True, show_dtype=True, show_layer_activations=True)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "iGS8KzdLTNFl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Addestramento del modello con implementazioni di callback e tensorboard"
      ],
      "metadata": {
        "id": "4QykN0ZJqFLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def run_experiment(model, learning_rate, weight_decay):\n",
        "    optimizer = tfa.optimizers.AdamW(learning_rate=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
        "        metrics=[\n",
        "            tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
        "            tf.keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "    checkpoint_filepath = \"checkpoint/\"\n",
        "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "\n",
        "    def custom_lr_scheduler(epoch, lr):\n",
        "      if lr < 1e-4:\n",
        "          return 6e-3\n",
        "      else:\n",
        "          return lr\n",
        "\n",
        "    lr_callback1 = LearningRateScheduler(custom_lr_scheduler)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    callback_LR = ReduceLROnPlateau(\n",
        "        patience = 2,\n",
        "        factor = 0.75,\n",
        "        monitor = 'loss',\n",
        "        mode = 'min',\n",
        "        min_lr = 1e-5,\n",
        "        verbose = 1)\n",
        "\n",
        "    history = model.fit(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[checkpoint_callback, tensorboard_callback, callback_LR, lr_callback1]\n",
        "\n",
        "\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "    model.save_weights(\"Pesi_CCT.h5\")\n",
        "    return history\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cct_model = create_cct_model()\n",
        "history = run_experiment(cct_model, learning_rate, weight_decay)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2EzppEPTQQQ",
        "outputId": "50918ec9-3acd-4901-a5d4-421a57267b36"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " data_augmentation (Sequent  (None, 32, 32, 3)            0         ['input_1[0][0]']             \n",
            " ial)                                                                                             \n",
            "                                                                                                  \n",
            " cct_tokenizer (CCTTokenize  (None, 64, 128)              75648     ['data_augmentation[0][0]']   \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOp  (None, 64, 128)              0         ['cct_tokenizer[0][0]']       \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " layer_normalization_4 (Lay  (None, 64, 128)              256       ['tf.__operators__.add[0][0]']\n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (Mu  (None, 64, 128)              263808    ['layer_normalization_4[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_4[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 64, 128)              0         ['multi_head_attention_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " stochastic_depth_4 (Stocha  (None, 64, 128)              0         ['tf.__operators__.add[0][0]',\n",
            " sticDepth)                                                          'dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            " layer_normalization_5 (Lay  (None, 64, 128)              256       ['stochastic_depth_4[0][0]']  \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 64, 128)              16512     ['layer_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)         (None, 64, 128)              0         ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 64, 128)              16512     ['dropout_9[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)        (None, 64, 128)              0         ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 64, 128)              16512     ['dropout_10[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)        (None, 64, 128)              0         ['dense_8[0][0]']             \n",
            "                                                                                                  \n",
            " stochastic_depth_5 (Stocha  (None, 64, 128)              0         ['stochastic_depth_4[0][0]',  \n",
            " sticDepth)                                                          'dropout_11[0][0]']          \n",
            "                                                                                                  \n",
            " stochastic_depth_6 (Stocha  (None, 64, 128)              0         ['stochastic_depth_5[0][0]',  \n",
            " sticDepth)                                                          'stochastic_depth_5[0][0]']  \n",
            "                                                                                                  \n",
            " layer_normalization_6 (Lay  (None, 64, 128)              256       ['stochastic_depth_6[0][0]']  \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 64, 1)                129       ['layer_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " tf.nn.softmax (TFOpLambda)  (None, 64, 1)                0         ['dense_9[0][0]']             \n",
            "                                                                                                  \n",
            " tf.linalg.matmul (TFOpLamb  (None, 1, 128)               0         ['tf.nn.softmax[0][0]',       \n",
            " da)                                                                 'layer_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " tf.compat.v1.squeeze (TFOp  (None, 128)                  0         ['tf.linalg.matmul[0][0]']    \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 100)                  12900     ['tf.compat.v1.squeeze[0][0]']\n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 402789 (1.54 MB)\n",
            "Trainable params: 402789 (1.54 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/500\n",
            "176/176 [==============================] - 10s 29ms/step - loss: 4.4236 - accuracy: 0.0470 - top-5-accuracy: 0.1663 - val_loss: 4.3445 - val_accuracy: 0.0530 - val_top-5-accuracy: 0.1896 - lr: 0.0050\n",
            "Epoch 2/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 4.0849 - accuracy: 0.0936 - top-5-accuracy: 0.2809 - val_loss: 4.0840 - val_accuracy: 0.0924 - val_top-5-accuracy: 0.2964 - lr: 0.0050\n",
            "Epoch 3/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.9492 - accuracy: 0.1178 - top-5-accuracy: 0.3363 - val_loss: 4.0835 - val_accuracy: 0.1012 - val_top-5-accuracy: 0.3012 - lr: 0.0050\n",
            "Epoch 4/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.7766 - accuracy: 0.1562 - top-5-accuracy: 0.4034 - val_loss: 3.8543 - val_accuracy: 0.1470 - val_top-5-accuracy: 0.3936 - lr: 0.0050\n",
            "Epoch 5/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.6931 - accuracy: 0.1746 - top-5-accuracy: 0.4368 - val_loss: 3.7829 - val_accuracy: 0.1600 - val_top-5-accuracy: 0.4154 - lr: 0.0050\n",
            "Epoch 6/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.5981 - accuracy: 0.1962 - top-5-accuracy: 0.4688 - val_loss: 3.8172 - val_accuracy: 0.1604 - val_top-5-accuracy: 0.4090 - lr: 0.0050\n",
            "Epoch 7/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.5581 - accuracy: 0.2079 - top-5-accuracy: 0.4873 - val_loss: 4.0571 - val_accuracy: 0.1302 - val_top-5-accuracy: 0.3530 - lr: 0.0050\n",
            "Epoch 8/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.4974 - accuracy: 0.2246 - top-5-accuracy: 0.5029 - val_loss: 3.7081 - val_accuracy: 0.1928 - val_top-5-accuracy: 0.4558 - lr: 0.0050\n",
            "Epoch 9/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.4934 - accuracy: 0.2229 - top-5-accuracy: 0.5089 - val_loss: 3.9251 - val_accuracy: 0.1474 - val_top-5-accuracy: 0.3900 - lr: 0.0050\n",
            "Epoch 10/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.4293 - accuracy: 0.2405 - top-5-accuracy: 0.5273 - val_loss: 3.8598 - val_accuracy: 0.1618 - val_top-5-accuracy: 0.4236 - lr: 0.0050\n",
            "Epoch 11/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.3994 - accuracy: 0.2463 - top-5-accuracy: 0.5342 - val_loss: 3.7072 - val_accuracy: 0.1920 - val_top-5-accuracy: 0.4652 - lr: 0.0050\n",
            "Epoch 12/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.3820 - accuracy: 0.2513 - top-5-accuracy: 0.5415 - val_loss: 3.5719 - val_accuracy: 0.2184 - val_top-5-accuracy: 0.4960 - lr: 0.0050\n",
            "Epoch 13/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.3298 - accuracy: 0.2638 - top-5-accuracy: 0.5601 - val_loss: 3.5813 - val_accuracy: 0.2104 - val_top-5-accuracy: 0.4988 - lr: 0.0050\n",
            "Epoch 14/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.3195 - accuracy: 0.2632 - top-5-accuracy: 0.5608 - val_loss: 3.5388 - val_accuracy: 0.2276 - val_top-5-accuracy: 0.5182 - lr: 0.0050\n",
            "Epoch 15/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.3013 - accuracy: 0.2694 - top-5-accuracy: 0.5673 - val_loss: 3.4299 - val_accuracy: 0.2394 - val_top-5-accuracy: 0.5358 - lr: 0.0050\n",
            "Epoch 16/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.3003 - accuracy: 0.2724 - top-5-accuracy: 0.5683 - val_loss: 3.4044 - val_accuracy: 0.2370 - val_top-5-accuracy: 0.5520 - lr: 0.0050\n",
            "Epoch 17/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.2545 - accuracy: 0.2815 - top-5-accuracy: 0.5808 - val_loss: 3.5603 - val_accuracy: 0.2330 - val_top-5-accuracy: 0.5160 - lr: 0.0050\n",
            "Epoch 18/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.2770 - accuracy: 0.2740 - top-5-accuracy: 0.5762 - val_loss: 3.4790 - val_accuracy: 0.2374 - val_top-5-accuracy: 0.5306 - lr: 0.0050\n",
            "Epoch 19/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.2410 - accuracy: 0.2856 - top-5-accuracy: 0.5844 - val_loss: 3.4521 - val_accuracy: 0.2488 - val_top-5-accuracy: 0.5410 - lr: 0.0050\n",
            "Epoch 20/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.2183 - accuracy: 0.2904 - top-5-accuracy: 0.5894 - val_loss: 3.3916 - val_accuracy: 0.2570 - val_top-5-accuracy: 0.5530 - lr: 0.0050\n",
            "Epoch 21/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.1815 - accuracy: 0.3037 - top-5-accuracy: 0.6016 - val_loss: 3.4593 - val_accuracy: 0.2506 - val_top-5-accuracy: 0.5492 - lr: 0.0050\n",
            "Epoch 22/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.1970 - accuracy: 0.2948 - top-5-accuracy: 0.5985 - val_loss: 3.4228 - val_accuracy: 0.2546 - val_top-5-accuracy: 0.5468 - lr: 0.0050\n",
            "Epoch 23/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.1725 - accuracy: 0.3059 - top-5-accuracy: 0.6046 - val_loss: 3.5149 - val_accuracy: 0.2458 - val_top-5-accuracy: 0.5312 - lr: 0.0050\n",
            "Epoch 24/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.1772 - accuracy: 0.3013 - top-5-accuracy: 0.6051 - val_loss: 3.4931 - val_accuracy: 0.2514 - val_top-5-accuracy: 0.5332 - lr: 0.0050\n",
            "Epoch 25/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.1347 - accuracy: 0.3146 - top-5-accuracy: 0.6163 - val_loss: 3.5298 - val_accuracy: 0.2384 - val_top-5-accuracy: 0.5342 - lr: 0.0050\n",
            "Epoch 26/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.1694 - accuracy: 0.3061 - top-5-accuracy: 0.6082 - val_loss: 3.4217 - val_accuracy: 0.2542 - val_top-5-accuracy: 0.5508 - lr: 0.0050\n",
            "Epoch 27/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.1311 - accuracy: 0.3135 - top-5-accuracy: 0.6202 - val_loss: 3.5005 - val_accuracy: 0.2434 - val_top-5-accuracy: 0.5328 - lr: 0.0050\n",
            "Epoch 28/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.1417 - accuracy: 0.3106 - top-5-accuracy: 0.6150 - val_loss: 3.4269 - val_accuracy: 0.2646 - val_top-5-accuracy: 0.5610 - lr: 0.0050\n",
            "Epoch 29/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.1020 - accuracy: 0.3209 - top-5-accuracy: 0.6267 - val_loss: 3.4507 - val_accuracy: 0.2724 - val_top-5-accuracy: 0.5574 - lr: 0.0050\n",
            "Epoch 30/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.1053 - accuracy: 0.3219 - top-5-accuracy: 0.6266 - val_loss: 3.4378 - val_accuracy: 0.2632 - val_top-5-accuracy: 0.5576 - lr: 0.0050\n",
            "Epoch 31/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.0976 - accuracy: 0.3216 - top-5-accuracy: 0.6282 - val_loss: 3.3720 - val_accuracy: 0.2768 - val_top-5-accuracy: 0.5716 - lr: 0.0050\n",
            "Epoch 32/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.0948 - accuracy: 0.3231 - top-5-accuracy: 0.6277 - val_loss: 3.4315 - val_accuracy: 0.2694 - val_top-5-accuracy: 0.5564 - lr: 0.0050\n",
            "Epoch 33/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.0880 - accuracy: 0.3274 - top-5-accuracy: 0.6291 - val_loss: 3.3782 - val_accuracy: 0.2666 - val_top-5-accuracy: 0.5762 - lr: 0.0050\n",
            "Epoch 34/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.0852 - accuracy: 0.3244 - top-5-accuracy: 0.6298 - val_loss: 3.2870 - val_accuracy: 0.2826 - val_top-5-accuracy: 0.5922 - lr: 0.0050\n",
            "Epoch 35/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.0778 - accuracy: 0.3294 - top-5-accuracy: 0.6317 - val_loss: 3.3412 - val_accuracy: 0.2816 - val_top-5-accuracy: 0.5822 - lr: 0.0050\n",
            "Epoch 36/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.0805 - accuracy: 0.3265 - top-5-accuracy: 0.6323 - val_loss: 3.3688 - val_accuracy: 0.2720 - val_top-5-accuracy: 0.5756 - lr: 0.0050\n",
            "Epoch 37/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.0579 - accuracy: 0.3343 - top-5-accuracy: 0.6364 - val_loss: 3.3549 - val_accuracy: 0.2770 - val_top-5-accuracy: 0.5834 - lr: 0.0050\n",
            "Epoch 38/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.0482 - accuracy: 0.3356 - top-5-accuracy: 0.6412 - val_loss: 3.3744 - val_accuracy: 0.2778 - val_top-5-accuracy: 0.5774 - lr: 0.0050\n",
            "Epoch 39/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.0449 - accuracy: 0.3367 - top-5-accuracy: 0.6427 - val_loss: 3.4369 - val_accuracy: 0.2630 - val_top-5-accuracy: 0.5512 - lr: 0.0050\n",
            "Epoch 40/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.0309 - accuracy: 0.3370 - top-5-accuracy: 0.6475 - val_loss: 3.3178 - val_accuracy: 0.2850 - val_top-5-accuracy: 0.5848 - lr: 0.0050\n",
            "Epoch 41/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.0219 - accuracy: 0.3448 - top-5-accuracy: 0.6474 - val_loss: 3.3629 - val_accuracy: 0.2736 - val_top-5-accuracy: 0.5792 - lr: 0.0050\n",
            "Epoch 42/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.0430 - accuracy: 0.3367 - top-5-accuracy: 0.6422 - val_loss: 3.3616 - val_accuracy: 0.2720 - val_top-5-accuracy: 0.5786 - lr: 0.0050\n",
            "Epoch 43/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 3.0122 - accuracy: 0.3470 - top-5-accuracy: 0.6487 - val_loss: 3.3240 - val_accuracy: 0.2764 - val_top-5-accuracy: 0.5884 - lr: 0.0050\n",
            "Epoch 44/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 2.9938 - accuracy: 0.3513 - top-5-accuracy: 0.6554 - val_loss: 3.2357 - val_accuracy: 0.3006 - val_top-5-accuracy: 0.6084 - lr: 0.0050\n",
            "Epoch 45/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.9951 - accuracy: 0.3487 - top-5-accuracy: 0.6586 - val_loss: 3.4014 - val_accuracy: 0.2802 - val_top-5-accuracy: 0.5808 - lr: 0.0050\n",
            "Epoch 46/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 2.9924 - accuracy: 0.3526 - top-5-accuracy: 0.6560 - val_loss: 3.3444 - val_accuracy: 0.2898 - val_top-5-accuracy: 0.5816 - lr: 0.0050\n",
            "Epoch 47/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.0077 - accuracy: 0.3462 - top-5-accuracy: 0.6509 - val_loss: 3.3283 - val_accuracy: 0.2704 - val_top-5-accuracy: 0.5878 - lr: 0.0050\n",
            "Epoch 48/500\n",
            "174/176 [============================>.] - ETA: 0s - loss: 2.9991 - accuracy: 0.3484 - top-5-accuracy: 0.6544\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0037499999161809683.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 3.0005 - accuracy: 0.3479 - top-5-accuracy: 0.6542 - val_loss: 3.2295 - val_accuracy: 0.3052 - val_top-5-accuracy: 0.6118 - lr: 0.0037\n",
            "Epoch 49/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.9517 - accuracy: 0.3594 - top-5-accuracy: 0.6681 - val_loss: 3.2964 - val_accuracy: 0.2886 - val_top-5-accuracy: 0.6012 - lr: 0.0037\n",
            "Epoch 50/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.9640 - accuracy: 0.3579 - top-5-accuracy: 0.6650 - val_loss: 3.2974 - val_accuracy: 0.2918 - val_top-5-accuracy: 0.5954 - lr: 0.0037\n",
            "Epoch 51/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 2.9302 - accuracy: 0.3666 - top-5-accuracy: 0.6728 - val_loss: 3.2403 - val_accuracy: 0.3038 - val_top-5-accuracy: 0.6222 - lr: 0.0037\n",
            "Epoch 52/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 2.9326 - accuracy: 0.3671 - top-5-accuracy: 0.6709 - val_loss: 3.3777 - val_accuracy: 0.2832 - val_top-5-accuracy: 0.5952 - lr: 0.0037\n",
            "Epoch 53/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 2.9299 - accuracy: 0.3675 - top-5-accuracy: 0.6735 - val_loss: 3.2543 - val_accuracy: 0.3006 - val_top-5-accuracy: 0.6178 - lr: 0.0037\n",
            "Epoch 54/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.9011 - accuracy: 0.3755 - top-5-accuracy: 0.6816 - val_loss: 3.3230 - val_accuracy: 0.2950 - val_top-5-accuracy: 0.5976 - lr: 0.0037\n",
            "Epoch 55/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.9514 - accuracy: 0.3614 - top-5-accuracy: 0.6677 - val_loss: 3.2457 - val_accuracy: 0.3064 - val_top-5-accuracy: 0.6052 - lr: 0.0037\n",
            "Epoch 56/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.9115 - accuracy: 0.3743 - top-5-accuracy: 0.6785\n",
            "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.002812499937135726.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.9112 - accuracy: 0.3742 - top-5-accuracy: 0.6786 - val_loss: 3.2430 - val_accuracy: 0.3006 - val_top-5-accuracy: 0.6044 - lr: 0.0028\n",
            "Epoch 57/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.8764 - accuracy: 0.3837 - top-5-accuracy: 0.6876 - val_loss: 3.1887 - val_accuracy: 0.3212 - val_top-5-accuracy: 0.6332 - lr: 0.0028\n",
            "Epoch 58/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.8707 - accuracy: 0.3822 - top-5-accuracy: 0.6889 - val_loss: 3.1935 - val_accuracy: 0.3152 - val_top-5-accuracy: 0.6266 - lr: 0.0028\n",
            "Epoch 59/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.8553 - accuracy: 0.3877 - top-5-accuracy: 0.6943 - val_loss: 3.2749 - val_accuracy: 0.3080 - val_top-5-accuracy: 0.6164 - lr: 0.0028\n",
            "Epoch 60/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.8709 - accuracy: 0.3841 - top-5-accuracy: 0.6892 - val_loss: 3.1483 - val_accuracy: 0.3326 - val_top-5-accuracy: 0.6458 - lr: 0.0028\n",
            "Epoch 61/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.8643 - accuracy: 0.3861 - top-5-accuracy: 0.6908\n",
            "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.002109374909196049.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.8638 - accuracy: 0.3860 - top-5-accuracy: 0.6910 - val_loss: 3.2442 - val_accuracy: 0.3054 - val_top-5-accuracy: 0.6224 - lr: 0.0021\n",
            "Epoch 62/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.8254 - accuracy: 0.3975 - top-5-accuracy: 0.7018 - val_loss: 3.1977 - val_accuracy: 0.3100 - val_top-5-accuracy: 0.6304 - lr: 0.0021\n",
            "Epoch 63/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.8282 - accuracy: 0.3960 - top-5-accuracy: 0.7003 - val_loss: 3.1891 - val_accuracy: 0.3198 - val_top-5-accuracy: 0.6344 - lr: 0.0021\n",
            "Epoch 64/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.8157 - accuracy: 0.4000 - top-5-accuracy: 0.7031 - val_loss: 3.2072 - val_accuracy: 0.3218 - val_top-5-accuracy: 0.6362 - lr: 0.0021\n",
            "Epoch 65/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.8341 - accuracy: 0.3953 - top-5-accuracy: 0.6995 - val_loss: 3.1999 - val_accuracy: 0.3178 - val_top-5-accuracy: 0.6304 - lr: 0.0021\n",
            "Epoch 66/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.8110 - accuracy: 0.4005 - top-5-accuracy: 0.7057 - val_loss: 3.2038 - val_accuracy: 0.3236 - val_top-5-accuracy: 0.6286 - lr: 0.0021\n",
            "Epoch 67/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.8093 - accuracy: 0.4016 - top-5-accuracy: 0.7060 - val_loss: 3.1475 - val_accuracy: 0.3312 - val_top-5-accuracy: 0.6404 - lr: 0.0021\n",
            "Epoch 68/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7828 - accuracy: 0.4084 - top-5-accuracy: 0.7120 - val_loss: 3.1567 - val_accuracy: 0.3326 - val_top-5-accuracy: 0.6520 - lr: 0.0021\n",
            "Epoch 69/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.8048 - accuracy: 0.4027 - top-5-accuracy: 0.7081 - val_loss: 3.1525 - val_accuracy: 0.3234 - val_top-5-accuracy: 0.6448 - lr: 0.0021\n",
            "Epoch 70/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7980 - accuracy: 0.4040 - top-5-accuracy: 0.7117\n",
            "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.001582031138241291.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7984 - accuracy: 0.4039 - top-5-accuracy: 0.7116 - val_loss: 3.1538 - val_accuracy: 0.3228 - val_top-5-accuracy: 0.6390 - lr: 0.0016\n",
            "Epoch 71/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7978 - accuracy: 0.4049 - top-5-accuracy: 0.7096 - val_loss: 3.1735 - val_accuracy: 0.3306 - val_top-5-accuracy: 0.6420 - lr: 0.0016\n",
            "Epoch 72/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7758 - accuracy: 0.4116 - top-5-accuracy: 0.7149 - val_loss: 3.1982 - val_accuracy: 0.3204 - val_top-5-accuracy: 0.6300 - lr: 0.0016\n",
            "Epoch 73/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7628 - accuracy: 0.4147 - top-5-accuracy: 0.7173 - val_loss: 3.1441 - val_accuracy: 0.3360 - val_top-5-accuracy: 0.6398 - lr: 0.0016\n",
            "Epoch 74/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7599 - accuracy: 0.4156 - top-5-accuracy: 0.7188 - val_loss: 3.1983 - val_accuracy: 0.3224 - val_top-5-accuracy: 0.6416 - lr: 0.0016\n",
            "Epoch 75/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7646 - accuracy: 0.4144 - top-5-accuracy: 0.7164 - val_loss: 3.1701 - val_accuracy: 0.3254 - val_top-5-accuracy: 0.6358 - lr: 0.0016\n",
            "Epoch 76/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7672 - accuracy: 0.4112 - top-5-accuracy: 0.7174\n",
            "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0011865233536809683.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7672 - accuracy: 0.4110 - top-5-accuracy: 0.7174 - val_loss: 3.1490 - val_accuracy: 0.3314 - val_top-5-accuracy: 0.6448 - lr: 0.0012\n",
            "Epoch 77/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7551 - accuracy: 0.4172 - top-5-accuracy: 0.7195 - val_loss: 3.1034 - val_accuracy: 0.3488 - val_top-5-accuracy: 0.6500 - lr: 0.0012\n",
            "Epoch 78/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7303 - accuracy: 0.4249 - top-5-accuracy: 0.7278 - val_loss: 3.1684 - val_accuracy: 0.3312 - val_top-5-accuracy: 0.6408 - lr: 0.0012\n",
            "Epoch 79/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7311 - accuracy: 0.4253 - top-5-accuracy: 0.7262 - val_loss: 3.0947 - val_accuracy: 0.3386 - val_top-5-accuracy: 0.6554 - lr: 0.0012\n",
            "Epoch 80/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7406 - accuracy: 0.4219 - top-5-accuracy: 0.7237\n",
            "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0008898925152607262.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7407 - accuracy: 0.4218 - top-5-accuracy: 0.7237 - val_loss: 3.1815 - val_accuracy: 0.3272 - val_top-5-accuracy: 0.6450 - lr: 8.8989e-04\n",
            "Epoch 81/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7292 - accuracy: 0.4232 - top-5-accuracy: 0.7268 - val_loss: 3.1499 - val_accuracy: 0.3320 - val_top-5-accuracy: 0.6468 - lr: 8.8989e-04\n",
            "Epoch 82/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7266 - accuracy: 0.4233 - top-5-accuracy: 0.7278 - val_loss: 3.1148 - val_accuracy: 0.3400 - val_top-5-accuracy: 0.6570 - lr: 8.8989e-04\n",
            "Epoch 83/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7212 - accuracy: 0.4277 - top-5-accuracy: 0.7300 - val_loss: 3.1121 - val_accuracy: 0.3394 - val_top-5-accuracy: 0.6502 - lr: 8.8989e-04\n",
            "Epoch 84/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7153 - accuracy: 0.4271 - top-5-accuracy: 0.7312 - val_loss: 3.0985 - val_accuracy: 0.3464 - val_top-5-accuracy: 0.6634 - lr: 8.8989e-04\n",
            "Epoch 85/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7223 - accuracy: 0.4252 - top-5-accuracy: 0.7289 - val_loss: 3.1102 - val_accuracy: 0.3412 - val_top-5-accuracy: 0.6572 - lr: 8.8989e-04\n",
            "Epoch 86/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7203 - accuracy: 0.4253 - top-5-accuracy: 0.7308\n",
            "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0006674193864455447.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7207 - accuracy: 0.4251 - top-5-accuracy: 0.7307 - val_loss: 3.1073 - val_accuracy: 0.3370 - val_top-5-accuracy: 0.6550 - lr: 6.6742e-04\n",
            "Epoch 87/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7120 - accuracy: 0.4308 - top-5-accuracy: 0.7315 - val_loss: 3.1027 - val_accuracy: 0.3450 - val_top-5-accuracy: 0.6552 - lr: 6.6742e-04\n",
            "Epoch 88/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7077 - accuracy: 0.4308 - top-5-accuracy: 0.7342 - val_loss: 3.0959 - val_accuracy: 0.3462 - val_top-5-accuracy: 0.6600 - lr: 6.6742e-04\n",
            "Epoch 89/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6974 - accuracy: 0.4352 - top-5-accuracy: 0.7352 - val_loss: 3.1386 - val_accuracy: 0.3396 - val_top-5-accuracy: 0.6458 - lr: 6.6742e-04\n",
            "Epoch 90/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6966 - accuracy: 0.4329 - top-5-accuracy: 0.7344 - val_loss: 3.1183 - val_accuracy: 0.3422 - val_top-5-accuracy: 0.6520 - lr: 6.6742e-04\n",
            "Epoch 91/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6994 - accuracy: 0.4336 - top-5-accuracy: 0.7341 - val_loss: 3.1096 - val_accuracy: 0.3388 - val_top-5-accuracy: 0.6528 - lr: 6.6742e-04\n",
            "Epoch 92/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7044 - accuracy: 0.4312 - top-5-accuracy: 0.7331\n",
            "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005005645507480949.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7042 - accuracy: 0.4312 - top-5-accuracy: 0.7332 - val_loss: 3.0858 - val_accuracy: 0.3492 - val_top-5-accuracy: 0.6644 - lr: 5.0056e-04\n",
            "Epoch 93/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7020 - accuracy: 0.4312 - top-5-accuracy: 0.7328 - val_loss: 3.1001 - val_accuracy: 0.3496 - val_top-5-accuracy: 0.6586 - lr: 5.0056e-04\n",
            "Epoch 94/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6815 - accuracy: 0.4403 - top-5-accuracy: 0.7398 - val_loss: 3.0830 - val_accuracy: 0.3486 - val_top-5-accuracy: 0.6620 - lr: 5.0056e-04\n",
            "Epoch 95/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6781 - accuracy: 0.4360 - top-5-accuracy: 0.7417 - val_loss: 3.0739 - val_accuracy: 0.3482 - val_top-5-accuracy: 0.6662 - lr: 5.0056e-04\n",
            "Epoch 96/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6876 - accuracy: 0.4378 - top-5-accuracy: 0.7364 - val_loss: 3.0797 - val_accuracy: 0.3446 - val_top-5-accuracy: 0.6686 - lr: 5.0056e-04\n",
            "Epoch 97/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6929 - accuracy: 0.4337 - top-5-accuracy: 0.7363\n",
            "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.00037542343488894403.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6924 - accuracy: 0.4337 - top-5-accuracy: 0.7366 - val_loss: 3.0783 - val_accuracy: 0.3478 - val_top-5-accuracy: 0.6670 - lr: 3.7542e-04\n",
            "Epoch 98/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6808 - accuracy: 0.4360 - top-5-accuracy: 0.7429 - val_loss: 3.0646 - val_accuracy: 0.3534 - val_top-5-accuracy: 0.6708 - lr: 3.7542e-04\n",
            "Epoch 99/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6769 - accuracy: 0.4416 - top-5-accuracy: 0.7404 - val_loss: 3.0575 - val_accuracy: 0.3530 - val_top-5-accuracy: 0.6722 - lr: 3.7542e-04\n",
            "Epoch 100/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6759 - accuracy: 0.4399 - top-5-accuracy: 0.7389 - val_loss: 3.0702 - val_accuracy: 0.3522 - val_top-5-accuracy: 0.6640 - lr: 3.7542e-04\n",
            "Epoch 101/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6803 - accuracy: 0.4368 - top-5-accuracy: 0.7406 - val_loss: 3.0791 - val_accuracy: 0.3514 - val_top-5-accuracy: 0.6664 - lr: 3.7542e-04\n",
            "Epoch 102/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6802 - accuracy: 0.4380 - top-5-accuracy: 0.7394\n",
            "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.000281567576166708.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6799 - accuracy: 0.4381 - top-5-accuracy: 0.7395 - val_loss: 3.0728 - val_accuracy: 0.3524 - val_top-5-accuracy: 0.6700 - lr: 2.8157e-04\n",
            "Epoch 103/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6686 - accuracy: 0.4408 - top-5-accuracy: 0.7422 - val_loss: 3.0744 - val_accuracy: 0.3502 - val_top-5-accuracy: 0.6714 - lr: 2.8157e-04\n",
            "Epoch 104/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6725 - accuracy: 0.4410 - top-5-accuracy: 0.7426 - val_loss: 3.0463 - val_accuracy: 0.3582 - val_top-5-accuracy: 0.6750 - lr: 2.8157e-04\n",
            "Epoch 105/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6590 - accuracy: 0.4454 - top-5-accuracy: 0.7450 - val_loss: 3.0585 - val_accuracy: 0.3566 - val_top-5-accuracy: 0.6682 - lr: 2.8157e-04\n",
            "Epoch 106/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6748 - accuracy: 0.4418 - top-5-accuracy: 0.7405 - val_loss: 3.0408 - val_accuracy: 0.3604 - val_top-5-accuracy: 0.6720 - lr: 2.8157e-04\n",
            "Epoch 107/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6695 - accuracy: 0.4423 - top-5-accuracy: 0.7415\n",
            "Epoch 107: ReduceLROnPlateau reducing learning rate to 0.0002111756766680628.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6693 - accuracy: 0.4423 - top-5-accuracy: 0.7415 - val_loss: 3.0505 - val_accuracy: 0.3592 - val_top-5-accuracy: 0.6734 - lr: 2.1118e-04\n",
            "Epoch 108/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6741 - accuracy: 0.4409 - top-5-accuracy: 0.7395 - val_loss: 3.0557 - val_accuracy: 0.3542 - val_top-5-accuracy: 0.6714 - lr: 2.1118e-04\n",
            "Epoch 109/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6642 - accuracy: 0.4437 - top-5-accuracy: 0.7445\n",
            "Epoch 109: ReduceLROnPlateau reducing learning rate to 0.0001583817575010471.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6640 - accuracy: 0.4437 - top-5-accuracy: 0.7446 - val_loss: 3.0548 - val_accuracy: 0.3556 - val_top-5-accuracy: 0.6710 - lr: 1.5838e-04\n",
            "Epoch 110/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6585 - accuracy: 0.4457 - top-5-accuracy: 0.7456 - val_loss: 3.0454 - val_accuracy: 0.3548 - val_top-5-accuracy: 0.6766 - lr: 1.5838e-04\n",
            "Epoch 111/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6641 - accuracy: 0.4427 - top-5-accuracy: 0.7434 - val_loss: 3.0436 - val_accuracy: 0.3594 - val_top-5-accuracy: 0.6728 - lr: 1.5838e-04\n",
            "Epoch 112/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6551 - accuracy: 0.4471 - top-5-accuracy: 0.7478 - val_loss: 3.0511 - val_accuracy: 0.3558 - val_top-5-accuracy: 0.6750 - lr: 1.5838e-04\n",
            "Epoch 113/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6656 - accuracy: 0.4412 - top-5-accuracy: 0.7446 - val_loss: 3.0424 - val_accuracy: 0.3576 - val_top-5-accuracy: 0.6760 - lr: 1.5838e-04\n",
            "Epoch 114/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6669 - accuracy: 0.4425 - top-5-accuracy: 0.7437\n",
            "Epoch 114: ReduceLROnPlateau reducing learning rate to 0.00011878632358275354.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6664 - accuracy: 0.4427 - top-5-accuracy: 0.7437 - val_loss: 3.0291 - val_accuracy: 0.3592 - val_top-5-accuracy: 0.6782 - lr: 1.1879e-04\n",
            "Epoch 115/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6481 - accuracy: 0.4487 - top-5-accuracy: 0.7477 - val_loss: 3.0513 - val_accuracy: 0.3562 - val_top-5-accuracy: 0.6706 - lr: 1.1879e-04\n",
            "Epoch 116/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6641 - accuracy: 0.4434 - top-5-accuracy: 0.7436 - val_loss: 3.0392 - val_accuracy: 0.3602 - val_top-5-accuracy: 0.6764 - lr: 1.1879e-04\n",
            "Epoch 117/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6615 - accuracy: 0.4422 - top-5-accuracy: 0.7442\n",
            "Epoch 117: ReduceLROnPlateau reducing learning rate to 8.908974268706515e-05.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6611 - accuracy: 0.4422 - top-5-accuracy: 0.7444 - val_loss: 3.0519 - val_accuracy: 0.3552 - val_top-5-accuracy: 0.6740 - lr: 8.9090e-05\n",
            "Epoch 118/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.9436 - accuracy: 0.3644 - top-5-accuracy: 0.6705 - val_loss: 3.3397 - val_accuracy: 0.2908 - val_top-5-accuracy: 0.5894 - lr: 0.0060\n",
            "Epoch 119/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.9193 - accuracy: 0.3708 - top-5-accuracy: 0.6774\n",
            "Epoch 119: ReduceLROnPlateau reducing learning rate to 0.004500000039115548.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.9190 - accuracy: 0.3706 - top-5-accuracy: 0.6775 - val_loss: 3.2141 - val_accuracy: 0.3156 - val_top-5-accuracy: 0.6206 - lr: 0.0045\n",
            "Epoch 120/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.8645 - accuracy: 0.3857 - top-5-accuracy: 0.6905 - val_loss: 3.1957 - val_accuracy: 0.3144 - val_top-5-accuracy: 0.6314 - lr: 0.0045\n",
            "Epoch 121/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.8358 - accuracy: 0.3919 - top-5-accuracy: 0.7010\n",
            "Epoch 121: ReduceLROnPlateau reducing learning rate to 0.0033749998547136784.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.8362 - accuracy: 0.3918 - top-5-accuracy: 0.7009 - val_loss: 3.2036 - val_accuracy: 0.3050 - val_top-5-accuracy: 0.6262 - lr: 0.0034\n",
            "Epoch 122/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.8044 - accuracy: 0.4029 - top-5-accuracy: 0.7090 - val_loss: 3.1798 - val_accuracy: 0.3266 - val_top-5-accuracy: 0.6382 - lr: 0.0034\n",
            "Epoch 123/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.8111 - accuracy: 0.4004 - top-5-accuracy: 0.7073\n",
            "Epoch 123: ReduceLROnPlateau reducing learning rate to 0.0025312498910352588.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.8106 - accuracy: 0.4005 - top-5-accuracy: 0.7075 - val_loss: 3.1476 - val_accuracy: 0.3292 - val_top-5-accuracy: 0.6344 - lr: 0.0025\n",
            "Epoch 124/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7867 - accuracy: 0.4068 - top-5-accuracy: 0.7110 - val_loss: 3.1031 - val_accuracy: 0.3358 - val_top-5-accuracy: 0.6518 - lr: 0.0025\n",
            "Epoch 125/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7787 - accuracy: 0.4101 - top-5-accuracy: 0.7167\n",
            "Epoch 125: ReduceLROnPlateau reducing learning rate to 0.0018984375055879354.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7790 - accuracy: 0.4102 - top-5-accuracy: 0.7165 - val_loss: 3.1517 - val_accuracy: 0.3278 - val_top-5-accuracy: 0.6382 - lr: 0.0019\n",
            "Epoch 126/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7509 - accuracy: 0.4185 - top-5-accuracy: 0.7213 - val_loss: 3.1719 - val_accuracy: 0.3266 - val_top-5-accuracy: 0.6410 - lr: 0.0019\n",
            "Epoch 127/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7378 - accuracy: 0.4201 - top-5-accuracy: 0.7237\n",
            "Epoch 127: ReduceLROnPlateau reducing learning rate to 0.0014238281291909516.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7380 - accuracy: 0.4201 - top-5-accuracy: 0.7237 - val_loss: 3.1554 - val_accuracy: 0.3290 - val_top-5-accuracy: 0.6480 - lr: 0.0014\n",
            "Epoch 128/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7097 - accuracy: 0.4281 - top-5-accuracy: 0.7338 - val_loss: 3.0951 - val_accuracy: 0.3482 - val_top-5-accuracy: 0.6630 - lr: 0.0014\n",
            "Epoch 129/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7156 - accuracy: 0.4258 - top-5-accuracy: 0.7313\n",
            "Epoch 129: ReduceLROnPlateau reducing learning rate to 0.001067871053237468.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7162 - accuracy: 0.4255 - top-5-accuracy: 0.7312 - val_loss: 3.0420 - val_accuracy: 0.3578 - val_top-5-accuracy: 0.6724 - lr: 0.0011\n",
            "Epoch 130/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6941 - accuracy: 0.4368 - top-5-accuracy: 0.7363 - val_loss: 3.1087 - val_accuracy: 0.3464 - val_top-5-accuracy: 0.6592 - lr: 0.0011\n",
            "Epoch 131/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6923 - accuracy: 0.4327 - top-5-accuracy: 0.7367\n",
            "Epoch 131: ReduceLROnPlateau reducing learning rate to 0.0008009032462723553.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6918 - accuracy: 0.4329 - top-5-accuracy: 0.7369 - val_loss: 3.0945 - val_accuracy: 0.3498 - val_top-5-accuracy: 0.6628 - lr: 8.0090e-04\n",
            "Epoch 132/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6808 - accuracy: 0.4391 - top-5-accuracy: 0.7395 - val_loss: 3.1164 - val_accuracy: 0.3422 - val_top-5-accuracy: 0.6592 - lr: 8.0090e-04\n",
            "Epoch 133/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6779 - accuracy: 0.4392 - top-5-accuracy: 0.7413\n",
            "Epoch 133: ReduceLROnPlateau reducing learning rate to 0.0006006774347042665.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6770 - accuracy: 0.4394 - top-5-accuracy: 0.7416 - val_loss: 3.0690 - val_accuracy: 0.3574 - val_top-5-accuracy: 0.6690 - lr: 6.0068e-04\n",
            "Epoch 134/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6704 - accuracy: 0.4393 - top-5-accuracy: 0.7424 - val_loss: 3.0204 - val_accuracy: 0.3632 - val_top-5-accuracy: 0.6830 - lr: 6.0068e-04\n",
            "Epoch 135/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6761 - accuracy: 0.4394 - top-5-accuracy: 0.7393\n",
            "Epoch 135: ReduceLROnPlateau reducing learning rate to 0.0004505080869421363.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6756 - accuracy: 0.4396 - top-5-accuracy: 0.7394 - val_loss: 3.0606 - val_accuracy: 0.3546 - val_top-5-accuracy: 0.6704 - lr: 4.5051e-04\n",
            "Epoch 136/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6652 - accuracy: 0.4410 - top-5-accuracy: 0.7456 - val_loss: 3.0728 - val_accuracy: 0.3530 - val_top-5-accuracy: 0.6684 - lr: 4.5051e-04\n",
            "Epoch 137/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6489 - accuracy: 0.4478 - top-5-accuracy: 0.7457\n",
            "Epoch 137: ReduceLROnPlateau reducing learning rate to 0.0003378810652066022.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6493 - accuracy: 0.4477 - top-5-accuracy: 0.7456 - val_loss: 3.0619 - val_accuracy: 0.3522 - val_top-5-accuracy: 0.6720 - lr: 3.3788e-04\n",
            "Epoch 138/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 2.6423 - accuracy: 0.4490 - top-5-accuracy: 0.7497 - val_loss: 3.0430 - val_accuracy: 0.3594 - val_top-5-accuracy: 0.6748 - lr: 3.3788e-04\n",
            "Epoch 139/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6567 - accuracy: 0.4458 - top-5-accuracy: 0.7448 - val_loss: 3.0203 - val_accuracy: 0.3602 - val_top-5-accuracy: 0.6784 - lr: 3.3788e-04\n",
            "Epoch 140/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6578 - accuracy: 0.4443 - top-5-accuracy: 0.7462\n",
            "Epoch 140: ReduceLROnPlateau reducing learning rate to 0.00025341079890495166.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6575 - accuracy: 0.4442 - top-5-accuracy: 0.7462 - val_loss: 3.0268 - val_accuracy: 0.3612 - val_top-5-accuracy: 0.6786 - lr: 2.5341e-04\n",
            "Epoch 141/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 2.6338 - accuracy: 0.4527 - top-5-accuracy: 0.7501 - val_loss: 3.0323 - val_accuracy: 0.3556 - val_top-5-accuracy: 0.6768 - lr: 2.5341e-04\n",
            "Epoch 142/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6430 - accuracy: 0.4497 - top-5-accuracy: 0.7482 - val_loss: 3.0673 - val_accuracy: 0.3550 - val_top-5-accuracy: 0.6704 - lr: 2.5341e-04\n",
            "Epoch 143/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6493 - accuracy: 0.4495 - top-5-accuracy: 0.7485\n",
            "Epoch 143: ReduceLROnPlateau reducing learning rate to 0.00019005810463568196.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6495 - accuracy: 0.4494 - top-5-accuracy: 0.7486 - val_loss: 3.0338 - val_accuracy: 0.3628 - val_top-5-accuracy: 0.6784 - lr: 1.9006e-04\n",
            "Epoch 144/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6377 - accuracy: 0.4508 - top-5-accuracy: 0.7505 - val_loss: 3.0149 - val_accuracy: 0.3640 - val_top-5-accuracy: 0.6780 - lr: 1.9006e-04\n",
            "Epoch 145/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6336 - accuracy: 0.4531 - top-5-accuracy: 0.7523\n",
            "Epoch 145: ReduceLROnPlateau reducing learning rate to 0.00014254358393372968.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6341 - accuracy: 0.4531 - top-5-accuracy: 0.7520 - val_loss: 3.0342 - val_accuracy: 0.3590 - val_top-5-accuracy: 0.6776 - lr: 1.4254e-04\n",
            "Epoch 146/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6411 - accuracy: 0.4479 - top-5-accuracy: 0.7489 - val_loss: 3.0212 - val_accuracy: 0.3592 - val_top-5-accuracy: 0.6764 - lr: 1.4254e-04\n",
            "Epoch 147/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6288 - accuracy: 0.4524 - top-5-accuracy: 0.7549 - val_loss: 3.0249 - val_accuracy: 0.3606 - val_top-5-accuracy: 0.6768 - lr: 1.4254e-04\n",
            "Epoch 148/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6424 - accuracy: 0.4492 - top-5-accuracy: 0.7494 - val_loss: 3.0394 - val_accuracy: 0.3594 - val_top-5-accuracy: 0.6728 - lr: 1.4254e-04\n",
            "Epoch 149/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6377 - accuracy: 0.4488 - top-5-accuracy: 0.7512\n",
            "Epoch 149: ReduceLROnPlateau reducing learning rate to 0.00010690768249332905.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6372 - accuracy: 0.4491 - top-5-accuracy: 0.7513 - val_loss: 3.0124 - val_accuracy: 0.3642 - val_top-5-accuracy: 0.6792 - lr: 1.0691e-04\n",
            "Epoch 150/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6350 - accuracy: 0.4521 - top-5-accuracy: 0.7506 - val_loss: 3.0078 - val_accuracy: 0.3664 - val_top-5-accuracy: 0.6814 - lr: 1.0691e-04\n",
            "Epoch 151/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 2.6274 - accuracy: 0.4549 - top-5-accuracy: 0.7534 - val_loss: 3.0188 - val_accuracy: 0.3660 - val_top-5-accuracy: 0.6804 - lr: 1.0691e-04\n",
            "Epoch 152/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6366 - accuracy: 0.4498 - top-5-accuracy: 0.7494 - val_loss: 3.0225 - val_accuracy: 0.3650 - val_top-5-accuracy: 0.6774 - lr: 1.0691e-04\n",
            "Epoch 153/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6422 - accuracy: 0.4474 - top-5-accuracy: 0.7485\n",
            "Epoch 153: ReduceLROnPlateau reducing learning rate to 8.018076186999679e-05.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6420 - accuracy: 0.4477 - top-5-accuracy: 0.7486 - val_loss: 3.0161 - val_accuracy: 0.3624 - val_top-5-accuracy: 0.6786 - lr: 8.0181e-05\n",
            "Epoch 154/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.8839 - accuracy: 0.3777 - top-5-accuracy: 0.6856 - val_loss: 3.2896 - val_accuracy: 0.3030 - val_top-5-accuracy: 0.6108 - lr: 0.0060\n",
            "Epoch 155/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.9146 - accuracy: 0.3719 - top-5-accuracy: 0.6785\n",
            "Epoch 155: ReduceLROnPlateau reducing learning rate to 0.004500000039115548.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.9156 - accuracy: 0.3717 - top-5-accuracy: 0.6781 - val_loss: 3.3268 - val_accuracy: 0.2870 - val_top-5-accuracy: 0.5972 - lr: 0.0045\n",
            "Epoch 156/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.8422 - accuracy: 0.3881 - top-5-accuracy: 0.6981 - val_loss: 3.2053 - val_accuracy: 0.3222 - val_top-5-accuracy: 0.6294 - lr: 0.0045\n",
            "Epoch 157/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.8301 - accuracy: 0.3940 - top-5-accuracy: 0.7005\n",
            "Epoch 157: ReduceLROnPlateau reducing learning rate to 0.0033749998547136784.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.8301 - accuracy: 0.3940 - top-5-accuracy: 0.7005 - val_loss: 3.1283 - val_accuracy: 0.3298 - val_top-5-accuracy: 0.6460 - lr: 0.0034\n",
            "Epoch 158/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7733 - accuracy: 0.4122 - top-5-accuracy: 0.7158 - val_loss: 3.1618 - val_accuracy: 0.3288 - val_top-5-accuracy: 0.6442 - lr: 0.0034\n",
            "Epoch 159/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7580 - accuracy: 0.4155 - top-5-accuracy: 0.7208\n",
            "Epoch 159: ReduceLROnPlateau reducing learning rate to 0.0025312498910352588.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7587 - accuracy: 0.4152 - top-5-accuracy: 0.7207 - val_loss: 3.2377 - val_accuracy: 0.3150 - val_top-5-accuracy: 0.6264 - lr: 0.0025\n",
            "Epoch 160/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7403 - accuracy: 0.4196 - top-5-accuracy: 0.7248 - val_loss: 3.0989 - val_accuracy: 0.3368 - val_top-5-accuracy: 0.6546 - lr: 0.0025\n",
            "Epoch 161/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7320 - accuracy: 0.4230 - top-5-accuracy: 0.7255\n",
            "Epoch 161: ReduceLROnPlateau reducing learning rate to 0.0018984375055879354.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7310 - accuracy: 0.4232 - top-5-accuracy: 0.7257 - val_loss: 3.1050 - val_accuracy: 0.3448 - val_top-5-accuracy: 0.6564 - lr: 0.0019\n",
            "Epoch 162/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7227 - accuracy: 0.4255 - top-5-accuracy: 0.7290 - val_loss: 3.0773 - val_accuracy: 0.3570 - val_top-5-accuracy: 0.6648 - lr: 0.0019\n",
            "Epoch 163/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6998 - accuracy: 0.4322 - top-5-accuracy: 0.7355\n",
            "Epoch 163: ReduceLROnPlateau reducing learning rate to 0.0014238281291909516.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7001 - accuracy: 0.4322 - top-5-accuracy: 0.7354 - val_loss: 3.1274 - val_accuracy: 0.3424 - val_top-5-accuracy: 0.6492 - lr: 0.0014\n",
            "Epoch 164/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6876 - accuracy: 0.4346 - top-5-accuracy: 0.7374 - val_loss: 3.0966 - val_accuracy: 0.3478 - val_top-5-accuracy: 0.6576 - lr: 0.0014\n",
            "Epoch 165/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6954 - accuracy: 0.4326 - top-5-accuracy: 0.7363\n",
            "Epoch 165: ReduceLROnPlateau reducing learning rate to 0.001067871053237468.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6956 - accuracy: 0.4326 - top-5-accuracy: 0.7362 - val_loss: 3.0815 - val_accuracy: 0.3568 - val_top-5-accuracy: 0.6656 - lr: 0.0011\n",
            "Epoch 166/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6779 - accuracy: 0.4396 - top-5-accuracy: 0.7386 - val_loss: 3.0336 - val_accuracy: 0.3636 - val_top-5-accuracy: 0.6764 - lr: 0.0011\n",
            "Epoch 167/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6556 - accuracy: 0.4469 - top-5-accuracy: 0.7467\n",
            "Epoch 167: ReduceLROnPlateau reducing learning rate to 0.0008009032462723553.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6557 - accuracy: 0.4468 - top-5-accuracy: 0.7465 - val_loss: 3.0642 - val_accuracy: 0.3596 - val_top-5-accuracy: 0.6718 - lr: 8.0090e-04\n",
            "Epoch 168/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6494 - accuracy: 0.4458 - top-5-accuracy: 0.7494 - val_loss: 3.0669 - val_accuracy: 0.3540 - val_top-5-accuracy: 0.6668 - lr: 8.0090e-04\n",
            "Epoch 169/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6483 - accuracy: 0.4479 - top-5-accuracy: 0.7488\n",
            "Epoch 169: ReduceLROnPlateau reducing learning rate to 0.0006006774347042665.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6489 - accuracy: 0.4477 - top-5-accuracy: 0.7487 - val_loss: 3.0394 - val_accuracy: 0.3610 - val_top-5-accuracy: 0.6756 - lr: 6.0068e-04\n",
            "Epoch 170/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6339 - accuracy: 0.4498 - top-5-accuracy: 0.7516 - val_loss: 3.0018 - val_accuracy: 0.3672 - val_top-5-accuracy: 0.6840 - lr: 6.0068e-04\n",
            "Epoch 171/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6337 - accuracy: 0.4509 - top-5-accuracy: 0.7498\n",
            "Epoch 171: ReduceLROnPlateau reducing learning rate to 0.0004505080869421363.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6343 - accuracy: 0.4508 - top-5-accuracy: 0.7497 - val_loss: 3.0287 - val_accuracy: 0.3628 - val_top-5-accuracy: 0.6784 - lr: 4.5051e-04\n",
            "Epoch 172/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6274 - accuracy: 0.4537 - top-5-accuracy: 0.7543 - val_loss: 3.0557 - val_accuracy: 0.3582 - val_top-5-accuracy: 0.6744 - lr: 4.5051e-04\n",
            "Epoch 173/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 2.6252 - accuracy: 0.4549 - top-5-accuracy: 0.7532 - val_loss: 3.0369 - val_accuracy: 0.3624 - val_top-5-accuracy: 0.6756 - lr: 4.5051e-04\n",
            "Epoch 174/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 2.6122 - accuracy: 0.4582 - top-5-accuracy: 0.7575 - val_loss: 3.0382 - val_accuracy: 0.3662 - val_top-5-accuracy: 0.6764 - lr: 4.5051e-04\n",
            "Epoch 175/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6228 - accuracy: 0.4548 - top-5-accuracy: 0.7528 - val_loss: 3.0278 - val_accuracy: 0.3700 - val_top-5-accuracy: 0.6778 - lr: 4.5051e-04\n",
            "Epoch 176/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6164 - accuracy: 0.4581 - top-5-accuracy: 0.7563\n",
            "Epoch 176: ReduceLROnPlateau reducing learning rate to 0.0003378810652066022.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6164 - accuracy: 0.4581 - top-5-accuracy: 0.7562 - val_loss: 3.0560 - val_accuracy: 0.3612 - val_top-5-accuracy: 0.6778 - lr: 3.3788e-04\n",
            "Epoch 177/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 2.6125 - accuracy: 0.4585 - top-5-accuracy: 0.7548 - val_loss: 3.0543 - val_accuracy: 0.3638 - val_top-5-accuracy: 0.6782 - lr: 3.3788e-04\n",
            "Epoch 178/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6201 - accuracy: 0.4558 - top-5-accuracy: 0.7545\n",
            "Epoch 178: ReduceLROnPlateau reducing learning rate to 0.00025341079890495166.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6199 - accuracy: 0.4560 - top-5-accuracy: 0.7547 - val_loss: 3.0375 - val_accuracy: 0.3672 - val_top-5-accuracy: 0.6784 - lr: 2.5341e-04\n",
            "Epoch 179/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6128 - accuracy: 0.4556 - top-5-accuracy: 0.7578 - val_loss: 3.0144 - val_accuracy: 0.3698 - val_top-5-accuracy: 0.6846 - lr: 2.5341e-04\n",
            "Epoch 180/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6253 - accuracy: 0.4539 - top-5-accuracy: 0.7549\n",
            "Epoch 180: ReduceLROnPlateau reducing learning rate to 0.00019005810463568196.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6259 - accuracy: 0.4538 - top-5-accuracy: 0.7549 - val_loss: 3.0145 - val_accuracy: 0.3716 - val_top-5-accuracy: 0.6860 - lr: 1.9006e-04\n",
            "Epoch 181/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6037 - accuracy: 0.4626 - top-5-accuracy: 0.7593 - val_loss: 3.0231 - val_accuracy: 0.3696 - val_top-5-accuracy: 0.6826 - lr: 1.9006e-04\n",
            "Epoch 182/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6043 - accuracy: 0.4601 - top-5-accuracy: 0.7586 - val_loss: 3.0154 - val_accuracy: 0.3716 - val_top-5-accuracy: 0.6822 - lr: 1.9006e-04\n",
            "Epoch 183/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5999 - accuracy: 0.4608 - top-5-accuracy: 0.7601 - val_loss: 2.9886 - val_accuracy: 0.3776 - val_top-5-accuracy: 0.6898 - lr: 1.9006e-04\n",
            "Epoch 184/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6016 - accuracy: 0.4623 - top-5-accuracy: 0.7581 - val_loss: 3.0083 - val_accuracy: 0.3726 - val_top-5-accuracy: 0.6902 - lr: 1.9006e-04\n",
            "Epoch 185/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6123 - accuracy: 0.4578 - top-5-accuracy: 0.7557\n",
            "Epoch 185: ReduceLROnPlateau reducing learning rate to 0.00014254358393372968.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6128 - accuracy: 0.4575 - top-5-accuracy: 0.7555 - val_loss: 2.9858 - val_accuracy: 0.3788 - val_top-5-accuracy: 0.6892 - lr: 1.4254e-04\n",
            "Epoch 186/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6017 - accuracy: 0.4577 - top-5-accuracy: 0.7596 - val_loss: 3.0067 - val_accuracy: 0.3710 - val_top-5-accuracy: 0.6838 - lr: 1.4254e-04\n",
            "Epoch 187/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6052 - accuracy: 0.4616 - top-5-accuracy: 0.7591\n",
            "Epoch 187: ReduceLROnPlateau reducing learning rate to 0.00010690768249332905.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6052 - accuracy: 0.4617 - top-5-accuracy: 0.7592 - val_loss: 3.0069 - val_accuracy: 0.3694 - val_top-5-accuracy: 0.6872 - lr: 1.0691e-04\n",
            "Epoch 188/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5989 - accuracy: 0.4615 - top-5-accuracy: 0.7606 - val_loss: 3.0006 - val_accuracy: 0.3742 - val_top-5-accuracy: 0.6842 - lr: 1.0691e-04\n",
            "Epoch 189/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5969 - accuracy: 0.4614 - top-5-accuracy: 0.7633 - val_loss: 2.9896 - val_accuracy: 0.3750 - val_top-5-accuracy: 0.6868 - lr: 1.0691e-04\n",
            "Epoch 190/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6133 - accuracy: 0.4568 - top-5-accuracy: 0.7567 - val_loss: 3.0054 - val_accuracy: 0.3732 - val_top-5-accuracy: 0.6834 - lr: 1.0691e-04\n",
            "Epoch 191/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6057 - accuracy: 0.4590 - top-5-accuracy: 0.7577\n",
            "Epoch 191: ReduceLROnPlateau reducing learning rate to 8.018076186999679e-05.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6064 - accuracy: 0.4588 - top-5-accuracy: 0.7575 - val_loss: 3.0081 - val_accuracy: 0.3708 - val_top-5-accuracy: 0.6830 - lr: 8.0181e-05\n",
            "Epoch 192/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.8833 - accuracy: 0.3822 - top-5-accuracy: 0.6848 - val_loss: 3.1646 - val_accuracy: 0.3182 - val_top-5-accuracy: 0.6268 - lr: 0.0060\n",
            "Epoch 193/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.8530 - accuracy: 0.3865 - top-5-accuracy: 0.6954\n",
            "Epoch 193: ReduceLROnPlateau reducing learning rate to 0.004500000039115548.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.8524 - accuracy: 0.3866 - top-5-accuracy: 0.6957 - val_loss: 3.2380 - val_accuracy: 0.3210 - val_top-5-accuracy: 0.6226 - lr: 0.0045\n",
            "Epoch 194/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.8082 - accuracy: 0.4020 - top-5-accuracy: 0.7058 - val_loss: 3.1177 - val_accuracy: 0.3320 - val_top-5-accuracy: 0.6508 - lr: 0.0045\n",
            "Epoch 195/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7916 - accuracy: 0.4013 - top-5-accuracy: 0.7113\n",
            "Epoch 195: ReduceLROnPlateau reducing learning rate to 0.0033749998547136784.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7919 - accuracy: 0.4010 - top-5-accuracy: 0.7113 - val_loss: 3.1676 - val_accuracy: 0.3278 - val_top-5-accuracy: 0.6382 - lr: 0.0034\n",
            "Epoch 196/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7573 - accuracy: 0.4144 - top-5-accuracy: 0.7177 - val_loss: 3.0754 - val_accuracy: 0.3440 - val_top-5-accuracy: 0.6650 - lr: 0.0034\n",
            "Epoch 197/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7402 - accuracy: 0.4207 - top-5-accuracy: 0.7254\n",
            "Epoch 197: ReduceLROnPlateau reducing learning rate to 0.0025312498910352588.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7406 - accuracy: 0.4207 - top-5-accuracy: 0.7251 - val_loss: 3.0155 - val_accuracy: 0.3586 - val_top-5-accuracy: 0.6792 - lr: 0.0025\n",
            "Epoch 198/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7084 - accuracy: 0.4290 - top-5-accuracy: 0.7303 - val_loss: 3.1139 - val_accuracy: 0.3388 - val_top-5-accuracy: 0.6576 - lr: 0.0025\n",
            "Epoch 199/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7096 - accuracy: 0.4287 - top-5-accuracy: 0.7310\n",
            "Epoch 199: ReduceLROnPlateau reducing learning rate to 0.0018984375055879354.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7088 - accuracy: 0.4289 - top-5-accuracy: 0.7312 - val_loss: 3.0613 - val_accuracy: 0.3488 - val_top-5-accuracy: 0.6706 - lr: 0.0019\n",
            "Epoch 200/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6658 - accuracy: 0.4408 - top-5-accuracy: 0.7445 - val_loss: 3.0255 - val_accuracy: 0.3608 - val_top-5-accuracy: 0.6794 - lr: 0.0019\n",
            "Epoch 201/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6941 - accuracy: 0.4327 - top-5-accuracy: 0.7355\n",
            "Epoch 201: ReduceLROnPlateau reducing learning rate to 0.0014238281291909516.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6943 - accuracy: 0.4324 - top-5-accuracy: 0.7355 - val_loss: 3.0593 - val_accuracy: 0.3566 - val_top-5-accuracy: 0.6728 - lr: 0.0014\n",
            "Epoch 202/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6713 - accuracy: 0.4410 - top-5-accuracy: 0.7431 - val_loss: 3.0347 - val_accuracy: 0.3654 - val_top-5-accuracy: 0.6806 - lr: 0.0014\n",
            "Epoch 203/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6512 - accuracy: 0.4437 - top-5-accuracy: 0.7475\n",
            "Epoch 203: ReduceLROnPlateau reducing learning rate to 0.001067871053237468.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6515 - accuracy: 0.4436 - top-5-accuracy: 0.7475 - val_loss: 3.0464 - val_accuracy: 0.3564 - val_top-5-accuracy: 0.6790 - lr: 0.0011\n",
            "Epoch 204/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6391 - accuracy: 0.4501 - top-5-accuracy: 0.7510 - val_loss: 3.0394 - val_accuracy: 0.3580 - val_top-5-accuracy: 0.6818 - lr: 0.0011\n",
            "Epoch 205/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6344 - accuracy: 0.4496 - top-5-accuracy: 0.7504\n",
            "Epoch 205: ReduceLROnPlateau reducing learning rate to 0.0008009032462723553.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6350 - accuracy: 0.4495 - top-5-accuracy: 0.7503 - val_loss: 3.0250 - val_accuracy: 0.3660 - val_top-5-accuracy: 0.6852 - lr: 8.0090e-04\n",
            "Epoch 206/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6249 - accuracy: 0.4546 - top-5-accuracy: 0.7538 - val_loss: 3.0310 - val_accuracy: 0.3652 - val_top-5-accuracy: 0.6786 - lr: 8.0090e-04\n",
            "Epoch 207/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6286 - accuracy: 0.4519 - top-5-accuracy: 0.7531\n",
            "Epoch 207: ReduceLROnPlateau reducing learning rate to 0.0006006774347042665.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6279 - accuracy: 0.4521 - top-5-accuracy: 0.7533 - val_loss: 3.0192 - val_accuracy: 0.3632 - val_top-5-accuracy: 0.6824 - lr: 6.0068e-04\n",
            "Epoch 208/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6021 - accuracy: 0.4589 - top-5-accuracy: 0.7591 - val_loss: 3.0057 - val_accuracy: 0.3700 - val_top-5-accuracy: 0.6880 - lr: 6.0068e-04\n",
            "Epoch 209/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6052 - accuracy: 0.4593 - top-5-accuracy: 0.7597\n",
            "Epoch 209: ReduceLROnPlateau reducing learning rate to 0.0004505080869421363.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6051 - accuracy: 0.4594 - top-5-accuracy: 0.7598 - val_loss: 3.0362 - val_accuracy: 0.3658 - val_top-5-accuracy: 0.6854 - lr: 4.5051e-04\n",
            "Epoch 210/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5975 - accuracy: 0.4620 - top-5-accuracy: 0.7606 - val_loss: 3.0166 - val_accuracy: 0.3702 - val_top-5-accuracy: 0.6874 - lr: 4.5051e-04\n",
            "Epoch 211/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6020 - accuracy: 0.4596 - top-5-accuracy: 0.7621\n",
            "Epoch 211: ReduceLROnPlateau reducing learning rate to 0.0003378810652066022.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6018 - accuracy: 0.4596 - top-5-accuracy: 0.7622 - val_loss: 2.9989 - val_accuracy: 0.3718 - val_top-5-accuracy: 0.6888 - lr: 3.3788e-04\n",
            "Epoch 212/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5974 - accuracy: 0.4608 - top-5-accuracy: 0.7620 - val_loss: 3.0162 - val_accuracy: 0.3692 - val_top-5-accuracy: 0.6882 - lr: 3.3788e-04\n",
            "Epoch 213/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5856 - accuracy: 0.4663 - top-5-accuracy: 0.7629 - val_loss: 2.9919 - val_accuracy: 0.3764 - val_top-5-accuracy: 0.6922 - lr: 3.3788e-04\n",
            "Epoch 214/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5968 - accuracy: 0.4617 - top-5-accuracy: 0.7615 - val_loss: 3.0028 - val_accuracy: 0.3770 - val_top-5-accuracy: 0.6868 - lr: 3.3788e-04\n",
            "Epoch 215/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5841 - accuracy: 0.4657 - top-5-accuracy: 0.7637 - val_loss: 2.9997 - val_accuracy: 0.3742 - val_top-5-accuracy: 0.6916 - lr: 3.3788e-04\n",
            "Epoch 216/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5926 - accuracy: 0.4626 - top-5-accuracy: 0.7626 - val_loss: 2.9977 - val_accuracy: 0.3706 - val_top-5-accuracy: 0.6884 - lr: 3.3788e-04\n",
            "Epoch 217/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5865 - accuracy: 0.4661 - top-5-accuracy: 0.7627\n",
            "Epoch 217: ReduceLROnPlateau reducing learning rate to 0.00025341079890495166.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5873 - accuracy: 0.4658 - top-5-accuracy: 0.7624 - val_loss: 2.9953 - val_accuracy: 0.3736 - val_top-5-accuracy: 0.6896 - lr: 2.5341e-04\n",
            "Epoch 218/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5954 - accuracy: 0.4607 - top-5-accuracy: 0.7603 - val_loss: 2.9975 - val_accuracy: 0.3714 - val_top-5-accuracy: 0.6884 - lr: 2.5341e-04\n",
            "Epoch 219/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5831 - accuracy: 0.4660 - top-5-accuracy: 0.7641 - val_loss: 2.9984 - val_accuracy: 0.3762 - val_top-5-accuracy: 0.6932 - lr: 2.5341e-04\n",
            "Epoch 220/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5845 - accuracy: 0.4641 - top-5-accuracy: 0.7634 - val_loss: 2.9969 - val_accuracy: 0.3714 - val_top-5-accuracy: 0.6874 - lr: 2.5341e-04\n",
            "Epoch 221/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5842 - accuracy: 0.4642 - top-5-accuracy: 0.7644\n",
            "Epoch 221: ReduceLROnPlateau reducing learning rate to 0.00019005810463568196.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5837 - accuracy: 0.4644 - top-5-accuracy: 0.7645 - val_loss: 2.9648 - val_accuracy: 0.3824 - val_top-5-accuracy: 0.6930 - lr: 1.9006e-04\n",
            "Epoch 222/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5814 - accuracy: 0.4660 - top-5-accuracy: 0.7632 - val_loss: 2.9861 - val_accuracy: 0.3770 - val_top-5-accuracy: 0.6918 - lr: 1.9006e-04\n",
            "Epoch 223/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5684 - accuracy: 0.4709 - top-5-accuracy: 0.7662 - val_loss: 2.9701 - val_accuracy: 0.3828 - val_top-5-accuracy: 0.6918 - lr: 1.9006e-04\n",
            "Epoch 224/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5774 - accuracy: 0.4671 - top-5-accuracy: 0.7653 - val_loss: 2.9776 - val_accuracy: 0.3792 - val_top-5-accuracy: 0.6920 - lr: 1.9006e-04\n",
            "Epoch 225/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5817 - accuracy: 0.4665 - top-5-accuracy: 0.7663\n",
            "Epoch 225: ReduceLROnPlateau reducing learning rate to 0.00014254358393372968.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5815 - accuracy: 0.4667 - top-5-accuracy: 0.7664 - val_loss: 2.9866 - val_accuracy: 0.3782 - val_top-5-accuracy: 0.6906 - lr: 1.4254e-04\n",
            "Epoch 226/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5750 - accuracy: 0.4663 - top-5-accuracy: 0.7681 - val_loss: 2.9964 - val_accuracy: 0.3780 - val_top-5-accuracy: 0.6868 - lr: 1.4254e-04\n",
            "Epoch 227/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5792 - accuracy: 0.4656 - top-5-accuracy: 0.7675\n",
            "Epoch 227: ReduceLROnPlateau reducing learning rate to 0.00010690768249332905.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5801 - accuracy: 0.4655 - top-5-accuracy: 0.7672 - val_loss: 2.9735 - val_accuracy: 0.3808 - val_top-5-accuracy: 0.6932 - lr: 1.0691e-04\n",
            "Epoch 228/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5712 - accuracy: 0.4697 - top-5-accuracy: 0.7677 - val_loss: 2.9695 - val_accuracy: 0.3816 - val_top-5-accuracy: 0.6934 - lr: 1.0691e-04\n",
            "Epoch 229/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5713 - accuracy: 0.4694 - top-5-accuracy: 0.7674\n",
            "Epoch 229: ReduceLROnPlateau reducing learning rate to 8.018076186999679e-05.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5719 - accuracy: 0.4692 - top-5-accuracy: 0.7672 - val_loss: 2.9838 - val_accuracy: 0.3818 - val_top-5-accuracy: 0.6936 - lr: 8.0181e-05\n",
            "Epoch 230/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.8486 - accuracy: 0.3880 - top-5-accuracy: 0.6962 - val_loss: 3.2304 - val_accuracy: 0.3200 - val_top-5-accuracy: 0.6146 - lr: 0.0060\n",
            "Epoch 231/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.8745 - accuracy: 0.3805 - top-5-accuracy: 0.6878\n",
            "Epoch 231: ReduceLROnPlateau reducing learning rate to 0.004500000039115548.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.8733 - accuracy: 0.3809 - top-5-accuracy: 0.6882 - val_loss: 3.2853 - val_accuracy: 0.3002 - val_top-5-accuracy: 0.6038 - lr: 0.0045\n",
            "Epoch 232/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.8063 - accuracy: 0.3972 - top-5-accuracy: 0.7085 - val_loss: 3.1769 - val_accuracy: 0.3254 - val_top-5-accuracy: 0.6420 - lr: 0.0045\n",
            "Epoch 233/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7970 - accuracy: 0.4014 - top-5-accuracy: 0.7122\n",
            "Epoch 233: ReduceLROnPlateau reducing learning rate to 0.0033749998547136784.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7976 - accuracy: 0.4013 - top-5-accuracy: 0.7119 - val_loss: 3.1515 - val_accuracy: 0.3310 - val_top-5-accuracy: 0.6440 - lr: 0.0034\n",
            "Epoch 234/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7345 - accuracy: 0.4197 - top-5-accuracy: 0.7266 - val_loss: 3.1242 - val_accuracy: 0.3416 - val_top-5-accuracy: 0.6556 - lr: 0.0034\n",
            "Epoch 235/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7237 - accuracy: 0.4239 - top-5-accuracy: 0.7269\n",
            "Epoch 235: ReduceLROnPlateau reducing learning rate to 0.0025312498910352588.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7235 - accuracy: 0.4240 - top-5-accuracy: 0.7270 - val_loss: 3.1472 - val_accuracy: 0.3384 - val_top-5-accuracy: 0.6568 - lr: 0.0025\n",
            "Epoch 236/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6988 - accuracy: 0.4295 - top-5-accuracy: 0.7345 - val_loss: 3.1281 - val_accuracy: 0.3362 - val_top-5-accuracy: 0.6496 - lr: 0.0025\n",
            "Epoch 237/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6870 - accuracy: 0.4355 - top-5-accuracy: 0.7390\n",
            "Epoch 237: ReduceLROnPlateau reducing learning rate to 0.0018984375055879354.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6865 - accuracy: 0.4357 - top-5-accuracy: 0.7391 - val_loss: 3.0340 - val_accuracy: 0.3588 - val_top-5-accuracy: 0.6740 - lr: 0.0019\n",
            "Epoch 238/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6520 - accuracy: 0.4421 - top-5-accuracy: 0.7468 - val_loss: 3.0337 - val_accuracy: 0.3610 - val_top-5-accuracy: 0.6740 - lr: 0.0019\n",
            "Epoch 239/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6563 - accuracy: 0.4432 - top-5-accuracy: 0.7482\n",
            "Epoch 239: ReduceLROnPlateau reducing learning rate to 0.0014238281291909516.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6567 - accuracy: 0.4430 - top-5-accuracy: 0.7482 - val_loss: 2.9636 - val_accuracy: 0.3776 - val_top-5-accuracy: 0.6872 - lr: 0.0014\n",
            "Epoch 240/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6367 - accuracy: 0.4474 - top-5-accuracy: 0.7518 - val_loss: 2.9796 - val_accuracy: 0.3814 - val_top-5-accuracy: 0.6802 - lr: 0.0014\n",
            "Epoch 241/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6151 - accuracy: 0.4582 - top-5-accuracy: 0.7564\n",
            "Epoch 241: ReduceLROnPlateau reducing learning rate to 0.001067871053237468.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6158 - accuracy: 0.4581 - top-5-accuracy: 0.7562 - val_loss: 3.0140 - val_accuracy: 0.3692 - val_top-5-accuracy: 0.6802 - lr: 0.0011\n",
            "Epoch 242/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6134 - accuracy: 0.4570 - top-5-accuracy: 0.7563 - val_loss: 2.9739 - val_accuracy: 0.3778 - val_top-5-accuracy: 0.6928 - lr: 0.0011\n",
            "Epoch 243/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6067 - accuracy: 0.4589 - top-5-accuracy: 0.7569\n",
            "Epoch 243: ReduceLROnPlateau reducing learning rate to 0.0008009032462723553.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6064 - accuracy: 0.4590 - top-5-accuracy: 0.7570 - val_loss: 2.9969 - val_accuracy: 0.3746 - val_top-5-accuracy: 0.6866 - lr: 8.0090e-04\n",
            "Epoch 244/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5941 - accuracy: 0.4630 - top-5-accuracy: 0.7618 - val_loss: 3.0518 - val_accuracy: 0.3606 - val_top-5-accuracy: 0.6740 - lr: 8.0090e-04\n",
            "Epoch 245/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5962 - accuracy: 0.4610 - top-5-accuracy: 0.7608\n",
            "Epoch 245: ReduceLROnPlateau reducing learning rate to 0.0006006774347042665.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5962 - accuracy: 0.4609 - top-5-accuracy: 0.7610 - val_loss: 2.9900 - val_accuracy: 0.3796 - val_top-5-accuracy: 0.6854 - lr: 6.0068e-04\n",
            "Epoch 246/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5893 - accuracy: 0.4657 - top-5-accuracy: 0.7617 - val_loss: 3.0117 - val_accuracy: 0.3722 - val_top-5-accuracy: 0.6802 - lr: 6.0068e-04\n",
            "Epoch 247/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5864 - accuracy: 0.4644 - top-5-accuracy: 0.7631\n",
            "Epoch 247: ReduceLROnPlateau reducing learning rate to 0.0004505080869421363.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5866 - accuracy: 0.4642 - top-5-accuracy: 0.7631 - val_loss: 2.9666 - val_accuracy: 0.3796 - val_top-5-accuracy: 0.6878 - lr: 4.5051e-04\n",
            "Epoch 248/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5823 - accuracy: 0.4642 - top-5-accuracy: 0.7646 - val_loss: 2.9485 - val_accuracy: 0.3852 - val_top-5-accuracy: 0.6964 - lr: 4.5051e-04\n",
            "Epoch 249/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5770 - accuracy: 0.4662 - top-5-accuracy: 0.7662\n",
            "Epoch 249: ReduceLROnPlateau reducing learning rate to 0.0003378810652066022.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5761 - accuracy: 0.4666 - top-5-accuracy: 0.7663 - val_loss: 2.9443 - val_accuracy: 0.3884 - val_top-5-accuracy: 0.6962 - lr: 3.3788e-04\n",
            "Epoch 250/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5659 - accuracy: 0.4691 - top-5-accuracy: 0.7686 - val_loss: 2.9692 - val_accuracy: 0.3802 - val_top-5-accuracy: 0.6868 - lr: 3.3788e-04\n",
            "Epoch 251/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5589 - accuracy: 0.4711 - top-5-accuracy: 0.7691 - val_loss: 2.9725 - val_accuracy: 0.3832 - val_top-5-accuracy: 0.6886 - lr: 3.3788e-04\n",
            "Epoch 252/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5616 - accuracy: 0.4722 - top-5-accuracy: 0.7684 - val_loss: 2.9825 - val_accuracy: 0.3780 - val_top-5-accuracy: 0.6840 - lr: 3.3788e-04\n",
            "Epoch 253/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5696 - accuracy: 0.4708 - top-5-accuracy: 0.7686\n",
            "Epoch 253: ReduceLROnPlateau reducing learning rate to 0.00025341079890495166.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5692 - accuracy: 0.4708 - top-5-accuracy: 0.7686 - val_loss: 2.9746 - val_accuracy: 0.3814 - val_top-5-accuracy: 0.6898 - lr: 2.5341e-04\n",
            "Epoch 254/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5612 - accuracy: 0.4767 - top-5-accuracy: 0.7708 - val_loss: 2.9658 - val_accuracy: 0.3834 - val_top-5-accuracy: 0.6916 - lr: 2.5341e-04\n",
            "Epoch 255/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5576 - accuracy: 0.4732 - top-5-accuracy: 0.7697 - val_loss: 2.9605 - val_accuracy: 0.3852 - val_top-5-accuracy: 0.6926 - lr: 2.5341e-04\n",
            "Epoch 256/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5601 - accuracy: 0.4718 - top-5-accuracy: 0.7690 - val_loss: 2.9543 - val_accuracy: 0.3856 - val_top-5-accuracy: 0.6936 - lr: 2.5341e-04\n",
            "Epoch 257/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5678 - accuracy: 0.4714 - top-5-accuracy: 0.7673\n",
            "Epoch 257: ReduceLROnPlateau reducing learning rate to 0.00019005810463568196.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5680 - accuracy: 0.4711 - top-5-accuracy: 0.7673 - val_loss: 2.9635 - val_accuracy: 0.3802 - val_top-5-accuracy: 0.6922 - lr: 1.9006e-04\n",
            "Epoch 258/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5607 - accuracy: 0.4712 - top-5-accuracy: 0.7700 - val_loss: 2.9557 - val_accuracy: 0.3822 - val_top-5-accuracy: 0.6928 - lr: 1.9006e-04\n",
            "Epoch 259/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5619 - accuracy: 0.4714 - top-5-accuracy: 0.7699\n",
            "Epoch 259: ReduceLROnPlateau reducing learning rate to 0.00014254358393372968.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5622 - accuracy: 0.4713 - top-5-accuracy: 0.7698 - val_loss: 2.9717 - val_accuracy: 0.3826 - val_top-5-accuracy: 0.6920 - lr: 1.4254e-04\n",
            "Epoch 260/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5588 - accuracy: 0.4727 - top-5-accuracy: 0.7698 - val_loss: 2.9489 - val_accuracy: 0.3878 - val_top-5-accuracy: 0.6926 - lr: 1.4254e-04\n",
            "Epoch 261/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5517 - accuracy: 0.4753 - top-5-accuracy: 0.7728 - val_loss: 2.9506 - val_accuracy: 0.3874 - val_top-5-accuracy: 0.6926 - lr: 1.4254e-04\n",
            "Epoch 262/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5622 - accuracy: 0.4698 - top-5-accuracy: 0.7702 - val_loss: 2.9507 - val_accuracy: 0.3900 - val_top-5-accuracy: 0.6948 - lr: 1.4254e-04\n",
            "Epoch 263/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5495 - accuracy: 0.4768 - top-5-accuracy: 0.7724 - val_loss: 2.9586 - val_accuracy: 0.3874 - val_top-5-accuracy: 0.6908 - lr: 1.4254e-04\n",
            "Epoch 264/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5504 - accuracy: 0.4782 - top-5-accuracy: 0.7727 - val_loss: 2.9414 - val_accuracy: 0.3900 - val_top-5-accuracy: 0.6934 - lr: 1.4254e-04\n",
            "Epoch 265/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5466 - accuracy: 0.4768 - top-5-accuracy: 0.7726 - val_loss: 2.9419 - val_accuracy: 0.3904 - val_top-5-accuracy: 0.6972 - lr: 1.4254e-04\n",
            "Epoch 266/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5571 - accuracy: 0.4723 - top-5-accuracy: 0.7713 - val_loss: 2.9645 - val_accuracy: 0.3838 - val_top-5-accuracy: 0.6910 - lr: 1.4254e-04\n",
            "Epoch 267/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5479 - accuracy: 0.4777 - top-5-accuracy: 0.7732\n",
            "Epoch 267: ReduceLROnPlateau reducing learning rate to 0.00010690768249332905.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5483 - accuracy: 0.4776 - top-5-accuracy: 0.7732 - val_loss: 2.9562 - val_accuracy: 0.3876 - val_top-5-accuracy: 0.6900 - lr: 1.0691e-04\n",
            "Epoch 268/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5456 - accuracy: 0.4786 - top-5-accuracy: 0.7749 - val_loss: 2.9600 - val_accuracy: 0.3840 - val_top-5-accuracy: 0.6922 - lr: 1.0691e-04\n",
            "Epoch 269/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5401 - accuracy: 0.4773 - top-5-accuracy: 0.7748 - val_loss: 2.9464 - val_accuracy: 0.3878 - val_top-5-accuracy: 0.6962 - lr: 1.0691e-04\n",
            "Epoch 270/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5492 - accuracy: 0.4760 - top-5-accuracy: 0.7748 - val_loss: 2.9528 - val_accuracy: 0.3848 - val_top-5-accuracy: 0.6938 - lr: 1.0691e-04\n",
            "Epoch 271/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5518 - accuracy: 0.4763 - top-5-accuracy: 0.7715\n",
            "Epoch 271: ReduceLROnPlateau reducing learning rate to 8.018076186999679e-05.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5520 - accuracy: 0.4764 - top-5-accuracy: 0.7714 - val_loss: 2.9375 - val_accuracy: 0.3900 - val_top-5-accuracy: 0.6948 - lr: 8.0181e-05\n",
            "Epoch 272/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.8156 - accuracy: 0.3978 - top-5-accuracy: 0.7057 - val_loss: 3.1608 - val_accuracy: 0.3198 - val_top-5-accuracy: 0.6416 - lr: 0.0060\n",
            "Epoch 273/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.8385 - accuracy: 0.3890 - top-5-accuracy: 0.7011\n",
            "Epoch 273: ReduceLROnPlateau reducing learning rate to 0.004500000039115548.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.8387 - accuracy: 0.3890 - top-5-accuracy: 0.7011 - val_loss: 3.3432 - val_accuracy: 0.2970 - val_top-5-accuracy: 0.6118 - lr: 0.0045\n",
            "Epoch 274/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7639 - accuracy: 0.4113 - top-5-accuracy: 0.7185 - val_loss: 3.0115 - val_accuracy: 0.3626 - val_top-5-accuracy: 0.6784 - lr: 0.0045\n",
            "Epoch 275/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7633 - accuracy: 0.4102 - top-5-accuracy: 0.7189\n",
            "Epoch 275: ReduceLROnPlateau reducing learning rate to 0.0033749998547136784.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7640 - accuracy: 0.4101 - top-5-accuracy: 0.7190 - val_loss: 3.0468 - val_accuracy: 0.3524 - val_top-5-accuracy: 0.6632 - lr: 0.0034\n",
            "Epoch 276/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7036 - accuracy: 0.4281 - top-5-accuracy: 0.7360 - val_loss: 3.1078 - val_accuracy: 0.3490 - val_top-5-accuracy: 0.6640 - lr: 0.0034\n",
            "Epoch 277/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6912 - accuracy: 0.4331 - top-5-accuracy: 0.7370\n",
            "Epoch 277: ReduceLROnPlateau reducing learning rate to 0.0025312498910352588.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6920 - accuracy: 0.4330 - top-5-accuracy: 0.7370 - val_loss: 2.9590 - val_accuracy: 0.3714 - val_top-5-accuracy: 0.6930 - lr: 0.0025\n",
            "Epoch 278/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6810 - accuracy: 0.4358 - top-5-accuracy: 0.7389 - val_loss: 3.0618 - val_accuracy: 0.3616 - val_top-5-accuracy: 0.6726 - lr: 0.0025\n",
            "Epoch 279/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6590 - accuracy: 0.4420 - top-5-accuracy: 0.7462\n",
            "Epoch 279: ReduceLROnPlateau reducing learning rate to 0.0018984375055879354.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6590 - accuracy: 0.4420 - top-5-accuracy: 0.7461 - val_loss: 3.0230 - val_accuracy: 0.3678 - val_top-5-accuracy: 0.6798 - lr: 0.0019\n",
            "Epoch 280/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6487 - accuracy: 0.4448 - top-5-accuracy: 0.7480 - val_loss: 2.9850 - val_accuracy: 0.3688 - val_top-5-accuracy: 0.6902 - lr: 0.0019\n",
            "Epoch 281/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6281 - accuracy: 0.4515 - top-5-accuracy: 0.7544\n",
            "Epoch 281: ReduceLROnPlateau reducing learning rate to 0.0014238281291909516.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6280 - accuracy: 0.4515 - top-5-accuracy: 0.7544 - val_loss: 3.0500 - val_accuracy: 0.3628 - val_top-5-accuracy: 0.6786 - lr: 0.0014\n",
            "Epoch 282/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6235 - accuracy: 0.4514 - top-5-accuracy: 0.7520 - val_loss: 3.0241 - val_accuracy: 0.3672 - val_top-5-accuracy: 0.6768 - lr: 0.0014\n",
            "Epoch 283/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6095 - accuracy: 0.4576 - top-5-accuracy: 0.7566\n",
            "Epoch 283: ReduceLROnPlateau reducing learning rate to 0.001067871053237468.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6089 - accuracy: 0.4576 - top-5-accuracy: 0.7569 - val_loss: 2.9470 - val_accuracy: 0.3832 - val_top-5-accuracy: 0.6986 - lr: 0.0011\n",
            "Epoch 284/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5873 - accuracy: 0.4633 - top-5-accuracy: 0.7631 - val_loss: 2.9971 - val_accuracy: 0.3770 - val_top-5-accuracy: 0.6904 - lr: 0.0011\n",
            "Epoch 285/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5831 - accuracy: 0.4641 - top-5-accuracy: 0.7620\n",
            "Epoch 285: ReduceLROnPlateau reducing learning rate to 0.0008009032462723553.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5839 - accuracy: 0.4639 - top-5-accuracy: 0.7618 - val_loss: 2.9606 - val_accuracy: 0.3786 - val_top-5-accuracy: 0.6926 - lr: 8.0090e-04\n",
            "Epoch 286/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5884 - accuracy: 0.4651 - top-5-accuracy: 0.7638 - val_loss: 2.9635 - val_accuracy: 0.3796 - val_top-5-accuracy: 0.6976 - lr: 8.0090e-04\n",
            "Epoch 287/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5729 - accuracy: 0.4685 - top-5-accuracy: 0.7689\n",
            "Epoch 287: ReduceLROnPlateau reducing learning rate to 0.0006006774347042665.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5736 - accuracy: 0.4683 - top-5-accuracy: 0.7688 - val_loss: 2.9779 - val_accuracy: 0.3822 - val_top-5-accuracy: 0.6960 - lr: 6.0068e-04\n",
            "Epoch 288/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5621 - accuracy: 0.4743 - top-5-accuracy: 0.7698 - val_loss: 2.9347 - val_accuracy: 0.3932 - val_top-5-accuracy: 0.7072 - lr: 6.0068e-04\n",
            "Epoch 289/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5659 - accuracy: 0.4707 - top-5-accuracy: 0.7671\n",
            "Epoch 289: ReduceLROnPlateau reducing learning rate to 0.0004505080869421363.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5655 - accuracy: 0.4709 - top-5-accuracy: 0.7670 - val_loss: 2.9618 - val_accuracy: 0.3866 - val_top-5-accuracy: 0.7006 - lr: 4.5051e-04\n",
            "Epoch 290/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5539 - accuracy: 0.4733 - top-5-accuracy: 0.7699 - val_loss: 2.9583 - val_accuracy: 0.3854 - val_top-5-accuracy: 0.6960 - lr: 4.5051e-04\n",
            "Epoch 291/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5589 - accuracy: 0.4720 - top-5-accuracy: 0.7705\n",
            "Epoch 291: ReduceLROnPlateau reducing learning rate to 0.0003378810652066022.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5596 - accuracy: 0.4718 - top-5-accuracy: 0.7703 - val_loss: 2.9388 - val_accuracy: 0.3876 - val_top-5-accuracy: 0.7052 - lr: 3.3788e-04\n",
            "Epoch 292/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5480 - accuracy: 0.4755 - top-5-accuracy: 0.7719 - val_loss: 2.9370 - val_accuracy: 0.3898 - val_top-5-accuracy: 0.7040 - lr: 3.3788e-04\n",
            "Epoch 293/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5425 - accuracy: 0.4781 - top-5-accuracy: 0.7746\n",
            "Epoch 293: ReduceLROnPlateau reducing learning rate to 0.00025341079890495166.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5416 - accuracy: 0.4783 - top-5-accuracy: 0.7748 - val_loss: 2.9524 - val_accuracy: 0.3842 - val_top-5-accuracy: 0.7014 - lr: 2.5341e-04\n",
            "Epoch 294/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5438 - accuracy: 0.4761 - top-5-accuracy: 0.7743 - val_loss: 2.9515 - val_accuracy: 0.3840 - val_top-5-accuracy: 0.7006 - lr: 2.5341e-04\n",
            "Epoch 295/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5422 - accuracy: 0.4781 - top-5-accuracy: 0.7732\n",
            "Epoch 295: ReduceLROnPlateau reducing learning rate to 0.00019005810463568196.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5423 - accuracy: 0.4781 - top-5-accuracy: 0.7734 - val_loss: 2.9412 - val_accuracy: 0.3904 - val_top-5-accuracy: 0.7018 - lr: 1.9006e-04\n",
            "Epoch 296/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5464 - accuracy: 0.4763 - top-5-accuracy: 0.7727 - val_loss: 2.9336 - val_accuracy: 0.3922 - val_top-5-accuracy: 0.7024 - lr: 1.9006e-04\n",
            "Epoch 297/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5381 - accuracy: 0.4790 - top-5-accuracy: 0.7755 - val_loss: 2.9367 - val_accuracy: 0.3918 - val_top-5-accuracy: 0.7028 - lr: 1.9006e-04\n",
            "Epoch 298/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5331 - accuracy: 0.4793 - top-5-accuracy: 0.7758 - val_loss: 2.9220 - val_accuracy: 0.3974 - val_top-5-accuracy: 0.7030 - lr: 1.9006e-04\n",
            "Epoch 299/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5328 - accuracy: 0.4815 - top-5-accuracy: 0.7761 - val_loss: 2.9239 - val_accuracy: 0.3944 - val_top-5-accuracy: 0.7046 - lr: 1.9006e-04\n",
            "Epoch 300/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5372 - accuracy: 0.4775 - top-5-accuracy: 0.7764 - val_loss: 2.9079 - val_accuracy: 0.4022 - val_top-5-accuracy: 0.7030 - lr: 1.9006e-04\n",
            "Epoch 301/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5380 - accuracy: 0.4790 - top-5-accuracy: 0.7742\n",
            "Epoch 301: ReduceLROnPlateau reducing learning rate to 0.00014254358393372968.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5374 - accuracy: 0.4792 - top-5-accuracy: 0.7743 - val_loss: 2.9199 - val_accuracy: 0.3972 - val_top-5-accuracy: 0.7040 - lr: 1.4254e-04\n",
            "Epoch 302/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5364 - accuracy: 0.4776 - top-5-accuracy: 0.7772 - val_loss: 2.9161 - val_accuracy: 0.3976 - val_top-5-accuracy: 0.7068 - lr: 1.4254e-04\n",
            "Epoch 303/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5235 - accuracy: 0.4834 - top-5-accuracy: 0.7799 - val_loss: 2.9261 - val_accuracy: 0.3962 - val_top-5-accuracy: 0.7056 - lr: 1.4254e-04\n",
            "Epoch 304/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5283 - accuracy: 0.4812 - top-5-accuracy: 0.7782 - val_loss: 2.9293 - val_accuracy: 0.3924 - val_top-5-accuracy: 0.7010 - lr: 1.4254e-04\n",
            "Epoch 305/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5340 - accuracy: 0.4803 - top-5-accuracy: 0.7778\n",
            "Epoch 305: ReduceLROnPlateau reducing learning rate to 0.00010690768249332905.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5337 - accuracy: 0.4803 - top-5-accuracy: 0.7779 - val_loss: 2.9270 - val_accuracy: 0.3960 - val_top-5-accuracy: 0.7060 - lr: 1.0691e-04\n",
            "Epoch 306/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5299 - accuracy: 0.4818 - top-5-accuracy: 0.7780 - val_loss: 2.9165 - val_accuracy: 0.4000 - val_top-5-accuracy: 0.7080 - lr: 1.0691e-04\n",
            "Epoch 307/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5257 - accuracy: 0.4830 - top-5-accuracy: 0.7778\n",
            "Epoch 307: ReduceLROnPlateau reducing learning rate to 8.018076186999679e-05.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5249 - accuracy: 0.4834 - top-5-accuracy: 0.7780 - val_loss: 2.9261 - val_accuracy: 0.3980 - val_top-5-accuracy: 0.7038 - lr: 8.0181e-05\n",
            "Epoch 308/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.8271 - accuracy: 0.3934 - top-5-accuracy: 0.7020 - val_loss: 3.1607 - val_accuracy: 0.3278 - val_top-5-accuracy: 0.6432 - lr: 0.0060\n",
            "Epoch 309/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7822 - accuracy: 0.4056 - top-5-accuracy: 0.7120\n",
            "Epoch 309: ReduceLROnPlateau reducing learning rate to 0.004500000039115548.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7820 - accuracy: 0.4058 - top-5-accuracy: 0.7121 - val_loss: 3.1380 - val_accuracy: 0.3378 - val_top-5-accuracy: 0.6478 - lr: 0.0045\n",
            "Epoch 310/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7299 - accuracy: 0.4206 - top-5-accuracy: 0.7279 - val_loss: 3.1335 - val_accuracy: 0.3422 - val_top-5-accuracy: 0.6594 - lr: 0.0045\n",
            "Epoch 311/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7531 - accuracy: 0.4147 - top-5-accuracy: 0.7223\n",
            "Epoch 311: ReduceLROnPlateau reducing learning rate to 0.0033749998547136784.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7543 - accuracy: 0.4144 - top-5-accuracy: 0.7219 - val_loss: 3.1301 - val_accuracy: 0.3370 - val_top-5-accuracy: 0.6530 - lr: 0.0034\n",
            "Epoch 312/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6893 - accuracy: 0.4353 - top-5-accuracy: 0.7374 - val_loss: 3.0461 - val_accuracy: 0.3612 - val_top-5-accuracy: 0.6684 - lr: 0.0034\n",
            "Epoch 313/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6850 - accuracy: 0.4345 - top-5-accuracy: 0.7392\n",
            "Epoch 313: ReduceLROnPlateau reducing learning rate to 0.0025312498910352588.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6844 - accuracy: 0.4347 - top-5-accuracy: 0.7394 - val_loss: 3.0491 - val_accuracy: 0.3612 - val_top-5-accuracy: 0.6696 - lr: 0.0025\n",
            "Epoch 314/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6747 - accuracy: 0.4366 - top-5-accuracy: 0.7405 - val_loss: 3.0096 - val_accuracy: 0.3724 - val_top-5-accuracy: 0.6796 - lr: 0.0025\n",
            "Epoch 315/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6587 - accuracy: 0.4429 - top-5-accuracy: 0.7448\n",
            "Epoch 315: ReduceLROnPlateau reducing learning rate to 0.0018984375055879354.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6581 - accuracy: 0.4430 - top-5-accuracy: 0.7451 - val_loss: 2.9993 - val_accuracy: 0.3724 - val_top-5-accuracy: 0.6810 - lr: 0.0019\n",
            "Epoch 316/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6235 - accuracy: 0.4532 - top-5-accuracy: 0.7524 - val_loss: 2.9783 - val_accuracy: 0.3800 - val_top-5-accuracy: 0.6898 - lr: 0.0019\n",
            "Epoch 317/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6226 - accuracy: 0.4528 - top-5-accuracy: 0.7537\n",
            "Epoch 317: ReduceLROnPlateau reducing learning rate to 0.0014238281291909516.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6236 - accuracy: 0.4525 - top-5-accuracy: 0.7535 - val_loss: 2.9835 - val_accuracy: 0.3782 - val_top-5-accuracy: 0.6886 - lr: 0.0014\n",
            "Epoch 318/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5919 - accuracy: 0.4622 - top-5-accuracy: 0.7622 - val_loss: 2.9350 - val_accuracy: 0.3922 - val_top-5-accuracy: 0.7004 - lr: 0.0014\n",
            "Epoch 319/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5920 - accuracy: 0.4617 - top-5-accuracy: 0.7624\n",
            "Epoch 319: ReduceLROnPlateau reducing learning rate to 0.001067871053237468.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5925 - accuracy: 0.4616 - top-5-accuracy: 0.7623 - val_loss: 2.9995 - val_accuracy: 0.3732 - val_top-5-accuracy: 0.6862 - lr: 0.0011\n",
            "Epoch 320/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5740 - accuracy: 0.4669 - top-5-accuracy: 0.7693 - val_loss: 2.9511 - val_accuracy: 0.3834 - val_top-5-accuracy: 0.7004 - lr: 0.0011\n",
            "Epoch 321/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5709 - accuracy: 0.4695 - top-5-accuracy: 0.7674\n",
            "Epoch 321: ReduceLROnPlateau reducing learning rate to 0.0008009032462723553.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5708 - accuracy: 0.4695 - top-5-accuracy: 0.7675 - val_loss: 2.9728 - val_accuracy: 0.3792 - val_top-5-accuracy: 0.6984 - lr: 8.0090e-04\n",
            "Epoch 322/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5557 - accuracy: 0.4736 - top-5-accuracy: 0.7710 - val_loss: 2.9465 - val_accuracy: 0.3830 - val_top-5-accuracy: 0.7026 - lr: 8.0090e-04\n",
            "Epoch 323/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5417 - accuracy: 0.4752 - top-5-accuracy: 0.7760\n",
            "Epoch 323: ReduceLROnPlateau reducing learning rate to 0.0006006774347042665.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5419 - accuracy: 0.4752 - top-5-accuracy: 0.7760 - val_loss: 2.9287 - val_accuracy: 0.3880 - val_top-5-accuracy: 0.7042 - lr: 6.0068e-04\n",
            "Epoch 324/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5412 - accuracy: 0.4779 - top-5-accuracy: 0.7754 - val_loss: 2.9279 - val_accuracy: 0.3926 - val_top-5-accuracy: 0.7040 - lr: 6.0068e-04\n",
            "Epoch 325/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5349 - accuracy: 0.4798 - top-5-accuracy: 0.7772\n",
            "Epoch 325: ReduceLROnPlateau reducing learning rate to 0.0004505080869421363.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5347 - accuracy: 0.4797 - top-5-accuracy: 0.7774 - val_loss: 2.9382 - val_accuracy: 0.3892 - val_top-5-accuracy: 0.7012 - lr: 4.5051e-04\n",
            "Epoch 326/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5384 - accuracy: 0.4790 - top-5-accuracy: 0.7753 - val_loss: 2.9302 - val_accuracy: 0.3870 - val_top-5-accuracy: 0.7040 - lr: 4.5051e-04\n",
            "Epoch 327/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5391 - accuracy: 0.4779 - top-5-accuracy: 0.7747\n",
            "Epoch 327: ReduceLROnPlateau reducing learning rate to 0.0003378810652066022.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5385 - accuracy: 0.4781 - top-5-accuracy: 0.7748 - val_loss: 2.9069 - val_accuracy: 0.3978 - val_top-5-accuracy: 0.7122 - lr: 3.3788e-04\n",
            "Epoch 328/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5282 - accuracy: 0.4793 - top-5-accuracy: 0.7788 - val_loss: 2.9314 - val_accuracy: 0.3962 - val_top-5-accuracy: 0.7084 - lr: 3.3788e-04\n",
            "Epoch 329/500\n",
            "174/176 [============================>.] - ETA: 0s - loss: 2.5318 - accuracy: 0.4794 - top-5-accuracy: 0.7766\n",
            "Epoch 329: ReduceLROnPlateau reducing learning rate to 0.00025341079890495166.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5318 - accuracy: 0.4797 - top-5-accuracy: 0.7765 - val_loss: 2.9228 - val_accuracy: 0.3966 - val_top-5-accuracy: 0.7112 - lr: 2.5341e-04\n",
            "Epoch 330/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5196 - accuracy: 0.4858 - top-5-accuracy: 0.7795 - val_loss: 2.9166 - val_accuracy: 0.3988 - val_top-5-accuracy: 0.7072 - lr: 2.5341e-04\n",
            "Epoch 331/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5277 - accuracy: 0.4794 - top-5-accuracy: 0.7769 - val_loss: 2.9156 - val_accuracy: 0.3976 - val_top-5-accuracy: 0.7092 - lr: 2.5341e-04\n",
            "Epoch 332/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5275 - accuracy: 0.4812 - top-5-accuracy: 0.7767\n",
            "Epoch 332: ReduceLROnPlateau reducing learning rate to 0.00019005810463568196.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5274 - accuracy: 0.4812 - top-5-accuracy: 0.7767 - val_loss: 2.9135 - val_accuracy: 0.3954 - val_top-5-accuracy: 0.7086 - lr: 1.9006e-04\n",
            "Epoch 333/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5178 - accuracy: 0.4848 - top-5-accuracy: 0.7795 - val_loss: 2.9039 - val_accuracy: 0.4012 - val_top-5-accuracy: 0.7128 - lr: 1.9006e-04\n",
            "Epoch 334/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5231 - accuracy: 0.4843 - top-5-accuracy: 0.7787 - val_loss: 2.9121 - val_accuracy: 0.3960 - val_top-5-accuracy: 0.7114 - lr: 1.9006e-04\n",
            "Epoch 335/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5197 - accuracy: 0.4834 - top-5-accuracy: 0.7793\n",
            "Epoch 335: ReduceLROnPlateau reducing learning rate to 0.00014254358393372968.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5194 - accuracy: 0.4836 - top-5-accuracy: 0.7793 - val_loss: 2.9192 - val_accuracy: 0.3968 - val_top-5-accuracy: 0.7118 - lr: 1.4254e-04\n",
            "Epoch 336/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5154 - accuracy: 0.4852 - top-5-accuracy: 0.7808 - val_loss: 2.9147 - val_accuracy: 0.3930 - val_top-5-accuracy: 0.7134 - lr: 1.4254e-04\n",
            "Epoch 337/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5205 - accuracy: 0.4858 - top-5-accuracy: 0.7797 - val_loss: 2.9062 - val_accuracy: 0.3956 - val_top-5-accuracy: 0.7138 - lr: 1.4254e-04\n",
            "Epoch 338/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5175 - accuracy: 0.4837 - top-5-accuracy: 0.7822\n",
            "Epoch 338: ReduceLROnPlateau reducing learning rate to 0.00010690768249332905.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5182 - accuracy: 0.4836 - top-5-accuracy: 0.7820 - val_loss: 2.9118 - val_accuracy: 0.3930 - val_top-5-accuracy: 0.7108 - lr: 1.0691e-04\n",
            "Epoch 339/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 2.5129 - accuracy: 0.4872 - top-5-accuracy: 0.7805 - val_loss: 2.9148 - val_accuracy: 0.3970 - val_top-5-accuracy: 0.7130 - lr: 1.0691e-04\n",
            "Epoch 340/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 2.5142 - accuracy: 0.4874 - top-5-accuracy: 0.7813 - val_loss: 2.9108 - val_accuracy: 0.3958 - val_top-5-accuracy: 0.7116 - lr: 1.0691e-04\n",
            "Epoch 341/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5191 - accuracy: 0.4835 - top-5-accuracy: 0.7810\n",
            "Epoch 341: ReduceLROnPlateau reducing learning rate to 8.018076186999679e-05.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5188 - accuracy: 0.4836 - top-5-accuracy: 0.7810 - val_loss: 2.9044 - val_accuracy: 0.3954 - val_top-5-accuracy: 0.7148 - lr: 8.0181e-05\n",
            "Epoch 342/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7862 - accuracy: 0.4084 - top-5-accuracy: 0.7139 - val_loss: 3.0774 - val_accuracy: 0.3450 - val_top-5-accuracy: 0.6572 - lr: 0.0060\n",
            "Epoch 343/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7690 - accuracy: 0.4093 - top-5-accuracy: 0.7173\n",
            "Epoch 343: ReduceLROnPlateau reducing learning rate to 0.004500000039115548.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7691 - accuracy: 0.4094 - top-5-accuracy: 0.7173 - val_loss: 3.1481 - val_accuracy: 0.3348 - val_top-5-accuracy: 0.6530 - lr: 0.0045\n",
            "Epoch 344/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7279 - accuracy: 0.4203 - top-5-accuracy: 0.7291 - val_loss: 3.0627 - val_accuracy: 0.3532 - val_top-5-accuracy: 0.6636 - lr: 0.0045\n",
            "Epoch 345/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7312 - accuracy: 0.4209 - top-5-accuracy: 0.7284\n",
            "Epoch 345: ReduceLROnPlateau reducing learning rate to 0.0033749998547136784.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7308 - accuracy: 0.4210 - top-5-accuracy: 0.7284 - val_loss: 3.0694 - val_accuracy: 0.3492 - val_top-5-accuracy: 0.6674 - lr: 0.0034\n",
            "Epoch 346/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6726 - accuracy: 0.4344 - top-5-accuracy: 0.7440 - val_loss: 3.0490 - val_accuracy: 0.3536 - val_top-5-accuracy: 0.6756 - lr: 0.0034\n",
            "Epoch 347/500\n",
            "176/176 [==============================] - ETA: 0s - loss: 2.6481 - accuracy: 0.4432 - top-5-accuracy: 0.7490\n",
            "Epoch 347: ReduceLROnPlateau reducing learning rate to 0.0025312498910352588.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6481 - accuracy: 0.4432 - top-5-accuracy: 0.7490 - val_loss: 3.0256 - val_accuracy: 0.3708 - val_top-5-accuracy: 0.6770 - lr: 0.0025\n",
            "Epoch 348/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6279 - accuracy: 0.4491 - top-5-accuracy: 0.7529 - val_loss: 2.9654 - val_accuracy: 0.3810 - val_top-5-accuracy: 0.6866 - lr: 0.0025\n",
            "Epoch 349/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6246 - accuracy: 0.4523 - top-5-accuracy: 0.7525\n",
            "Epoch 349: ReduceLROnPlateau reducing learning rate to 0.0018984375055879354.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6246 - accuracy: 0.4523 - top-5-accuracy: 0.7525 - val_loss: 2.9959 - val_accuracy: 0.3790 - val_top-5-accuracy: 0.6856 - lr: 0.0019\n",
            "Epoch 350/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5888 - accuracy: 0.4634 - top-5-accuracy: 0.7634 - val_loss: 3.0105 - val_accuracy: 0.3778 - val_top-5-accuracy: 0.6868 - lr: 0.0019\n",
            "Epoch 351/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6024 - accuracy: 0.4565 - top-5-accuracy: 0.7577\n",
            "Epoch 351: ReduceLROnPlateau reducing learning rate to 0.0014238281291909516.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6026 - accuracy: 0.4566 - top-5-accuracy: 0.7575 - val_loss: 2.9259 - val_accuracy: 0.3936 - val_top-5-accuracy: 0.7060 - lr: 0.0014\n",
            "Epoch 352/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5732 - accuracy: 0.4647 - top-5-accuracy: 0.7676 - val_loss: 2.9437 - val_accuracy: 0.3920 - val_top-5-accuracy: 0.6970 - lr: 0.0014\n",
            "Epoch 353/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5613 - accuracy: 0.4695 - top-5-accuracy: 0.7696\n",
            "Epoch 353: ReduceLROnPlateau reducing learning rate to 0.001067871053237468.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5617 - accuracy: 0.4693 - top-5-accuracy: 0.7694 - val_loss: 2.9412 - val_accuracy: 0.3968 - val_top-5-accuracy: 0.7008 - lr: 0.0011\n",
            "Epoch 354/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5450 - accuracy: 0.4778 - top-5-accuracy: 0.7737 - val_loss: 2.9547 - val_accuracy: 0.3920 - val_top-5-accuracy: 0.7000 - lr: 0.0011\n",
            "Epoch 355/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5539 - accuracy: 0.4731 - top-5-accuracy: 0.7719\n",
            "Epoch 355: ReduceLROnPlateau reducing learning rate to 0.0008009032462723553.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5539 - accuracy: 0.4732 - top-5-accuracy: 0.7718 - val_loss: 2.9591 - val_accuracy: 0.3930 - val_top-5-accuracy: 0.6990 - lr: 8.0090e-04\n",
            "Epoch 356/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5450 - accuracy: 0.4744 - top-5-accuracy: 0.7734 - val_loss: 2.9597 - val_accuracy: 0.3896 - val_top-5-accuracy: 0.7032 - lr: 8.0090e-04\n",
            "Epoch 357/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5341 - accuracy: 0.4808 - top-5-accuracy: 0.7764\n",
            "Epoch 357: ReduceLROnPlateau reducing learning rate to 0.0006006774347042665.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5338 - accuracy: 0.4808 - top-5-accuracy: 0.7764 - val_loss: 2.9324 - val_accuracy: 0.3970 - val_top-5-accuracy: 0.7036 - lr: 6.0068e-04\n",
            "Epoch 358/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5321 - accuracy: 0.4780 - top-5-accuracy: 0.7781 - val_loss: 2.9236 - val_accuracy: 0.3924 - val_top-5-accuracy: 0.7076 - lr: 6.0068e-04\n",
            "Epoch 359/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5213 - accuracy: 0.4842 - top-5-accuracy: 0.7810\n",
            "Epoch 359: ReduceLROnPlateau reducing learning rate to 0.0004505080869421363.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5218 - accuracy: 0.4841 - top-5-accuracy: 0.7809 - val_loss: 2.8961 - val_accuracy: 0.4032 - val_top-5-accuracy: 0.7118 - lr: 4.5051e-04\n",
            "Epoch 360/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5152 - accuracy: 0.4842 - top-5-accuracy: 0.7808 - val_loss: 2.8967 - val_accuracy: 0.4064 - val_top-5-accuracy: 0.7138 - lr: 4.5051e-04\n",
            "Epoch 361/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5158 - accuracy: 0.4865 - top-5-accuracy: 0.7825\n",
            "Epoch 361: ReduceLROnPlateau reducing learning rate to 0.0003378810652066022.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5159 - accuracy: 0.4864 - top-5-accuracy: 0.7824 - val_loss: 2.8985 - val_accuracy: 0.4032 - val_top-5-accuracy: 0.7128 - lr: 3.3788e-04\n",
            "Epoch 362/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5127 - accuracy: 0.4862 - top-5-accuracy: 0.7803 - val_loss: 2.9249 - val_accuracy: 0.4014 - val_top-5-accuracy: 0.7074 - lr: 3.3788e-04\n",
            "Epoch 363/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5186 - accuracy: 0.4838 - top-5-accuracy: 0.7806 - val_loss: 2.9048 - val_accuracy: 0.4052 - val_top-5-accuracy: 0.7128 - lr: 3.3788e-04\n",
            "Epoch 364/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5111 - accuracy: 0.4862 - top-5-accuracy: 0.7809 - val_loss: 2.9091 - val_accuracy: 0.4040 - val_top-5-accuracy: 0.7102 - lr: 3.3788e-04\n",
            "Epoch 365/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5096 - accuracy: 0.4884 - top-5-accuracy: 0.7832 - val_loss: 2.9102 - val_accuracy: 0.4034 - val_top-5-accuracy: 0.7092 - lr: 3.3788e-04\n",
            "Epoch 366/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5102 - accuracy: 0.4868 - top-5-accuracy: 0.7822 - val_loss: 2.8998 - val_accuracy: 0.4036 - val_top-5-accuracy: 0.7126 - lr: 3.3788e-04\n",
            "Epoch 367/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5094 - accuracy: 0.4886 - top-5-accuracy: 0.7823 - val_loss: 2.8872 - val_accuracy: 0.4094 - val_top-5-accuracy: 0.7172 - lr: 3.3788e-04\n",
            "Epoch 368/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5041 - accuracy: 0.4895 - top-5-accuracy: 0.7853 - val_loss: 2.8921 - val_accuracy: 0.4042 - val_top-5-accuracy: 0.7122 - lr: 3.3788e-04\n",
            "Epoch 369/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5017 - accuracy: 0.4906 - top-5-accuracy: 0.7840 - val_loss: 2.8938 - val_accuracy: 0.4068 - val_top-5-accuracy: 0.7146 - lr: 3.3788e-04\n",
            "Epoch 370/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4975 - accuracy: 0.4901 - top-5-accuracy: 0.7845 - val_loss: 2.9132 - val_accuracy: 0.4012 - val_top-5-accuracy: 0.7122 - lr: 3.3788e-04\n",
            "Epoch 371/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5014 - accuracy: 0.4886 - top-5-accuracy: 0.7854 - val_loss: 2.8933 - val_accuracy: 0.4076 - val_top-5-accuracy: 0.7144 - lr: 3.3788e-04\n",
            "Epoch 372/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4940 - accuracy: 0.4889 - top-5-accuracy: 0.7859 - val_loss: 2.9137 - val_accuracy: 0.4016 - val_top-5-accuracy: 0.7120 - lr: 3.3788e-04\n",
            "Epoch 373/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5079 - accuracy: 0.4862 - top-5-accuracy: 0.7824 - val_loss: 2.9201 - val_accuracy: 0.4020 - val_top-5-accuracy: 0.7086 - lr: 3.3788e-04\n",
            "Epoch 374/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5035 - accuracy: 0.4882 - top-5-accuracy: 0.7842\n",
            "Epoch 374: ReduceLROnPlateau reducing learning rate to 0.00025341079890495166.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5035 - accuracy: 0.4883 - top-5-accuracy: 0.7843 - val_loss: 2.8823 - val_accuracy: 0.4100 - val_top-5-accuracy: 0.7180 - lr: 2.5341e-04\n",
            "Epoch 375/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5008 - accuracy: 0.4922 - top-5-accuracy: 0.7823 - val_loss: 2.9040 - val_accuracy: 0.4040 - val_top-5-accuracy: 0.7106 - lr: 2.5341e-04\n",
            "Epoch 376/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4866 - accuracy: 0.4948 - top-5-accuracy: 0.7863 - val_loss: 2.8928 - val_accuracy: 0.4084 - val_top-5-accuracy: 0.7122 - lr: 2.5341e-04\n",
            "Epoch 377/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4928 - accuracy: 0.4928 - top-5-accuracy: 0.7874 - val_loss: 2.8961 - val_accuracy: 0.4102 - val_top-5-accuracy: 0.7144 - lr: 2.5341e-04\n",
            "Epoch 378/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5016 - accuracy: 0.4880 - top-5-accuracy: 0.7844\n",
            "Epoch 378: ReduceLROnPlateau reducing learning rate to 0.00019005810463568196.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5014 - accuracy: 0.4881 - top-5-accuracy: 0.7846 - val_loss: 2.8890 - val_accuracy: 0.4042 - val_top-5-accuracy: 0.7144 - lr: 1.9006e-04\n",
            "Epoch 379/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4882 - accuracy: 0.4920 - top-5-accuracy: 0.7888 - val_loss: 2.8840 - val_accuracy: 0.4078 - val_top-5-accuracy: 0.7146 - lr: 1.9006e-04\n",
            "Epoch 380/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4929 - accuracy: 0.4924 - top-5-accuracy: 0.7867\n",
            "Epoch 380: ReduceLROnPlateau reducing learning rate to 0.00014254358393372968.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4917 - accuracy: 0.4929 - top-5-accuracy: 0.7868 - val_loss: 2.8956 - val_accuracy: 0.4096 - val_top-5-accuracy: 0.7140 - lr: 1.4254e-04\n",
            "Epoch 381/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4942 - accuracy: 0.4907 - top-5-accuracy: 0.7863 - val_loss: 2.8978 - val_accuracy: 0.4078 - val_top-5-accuracy: 0.7112 - lr: 1.4254e-04\n",
            "Epoch 382/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4902 - accuracy: 0.4939 - top-5-accuracy: 0.7885\n",
            "Epoch 382: ReduceLROnPlateau reducing learning rate to 0.00010690768249332905.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4890 - accuracy: 0.4945 - top-5-accuracy: 0.7888 - val_loss: 2.8896 - val_accuracy: 0.4108 - val_top-5-accuracy: 0.7140 - lr: 1.0691e-04\n",
            "Epoch 383/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4889 - accuracy: 0.4927 - top-5-accuracy: 0.7886 - val_loss: 2.8945 - val_accuracy: 0.4072 - val_top-5-accuracy: 0.7132 - lr: 1.0691e-04\n",
            "Epoch 384/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4923 - accuracy: 0.4931 - top-5-accuracy: 0.7873\n",
            "Epoch 384: ReduceLROnPlateau reducing learning rate to 8.018076186999679e-05.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4920 - accuracy: 0.4933 - top-5-accuracy: 0.7872 - val_loss: 2.8867 - val_accuracy: 0.4108 - val_top-5-accuracy: 0.7132 - lr: 8.0181e-05\n",
            "Epoch 385/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7806 - accuracy: 0.4088 - top-5-accuracy: 0.7158 - val_loss: 3.0502 - val_accuracy: 0.3572 - val_top-5-accuracy: 0.6742 - lr: 0.0060\n",
            "Epoch 386/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7602 - accuracy: 0.4109 - top-5-accuracy: 0.7177\n",
            "Epoch 386: ReduceLROnPlateau reducing learning rate to 0.004500000039115548.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7604 - accuracy: 0.4110 - top-5-accuracy: 0.7175 - val_loss: 3.2136 - val_accuracy: 0.3218 - val_top-5-accuracy: 0.6300 - lr: 0.0045\n",
            "Epoch 387/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6927 - accuracy: 0.4300 - top-5-accuracy: 0.7364 - val_loss: 3.1147 - val_accuracy: 0.3440 - val_top-5-accuracy: 0.6590 - lr: 0.0045\n",
            "Epoch 388/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6819 - accuracy: 0.4342 - top-5-accuracy: 0.7415\n",
            "Epoch 388: ReduceLROnPlateau reducing learning rate to 0.0033749998547136784.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6829 - accuracy: 0.4339 - top-5-accuracy: 0.7413 - val_loss: 3.0317 - val_accuracy: 0.3678 - val_top-5-accuracy: 0.6690 - lr: 0.0034\n",
            "Epoch 389/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6531 - accuracy: 0.4411 - top-5-accuracy: 0.7459 - val_loss: 2.9748 - val_accuracy: 0.3794 - val_top-5-accuracy: 0.6940 - lr: 0.0034\n",
            "Epoch 390/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6375 - accuracy: 0.4498 - top-5-accuracy: 0.7533\n",
            "Epoch 390: ReduceLROnPlateau reducing learning rate to 0.0025312498910352588.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6370 - accuracy: 0.4502 - top-5-accuracy: 0.7534 - val_loss: 3.0440 - val_accuracy: 0.3562 - val_top-5-accuracy: 0.6766 - lr: 0.0025\n",
            "Epoch 391/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6142 - accuracy: 0.4580 - top-5-accuracy: 0.7556 - val_loss: 2.9168 - val_accuracy: 0.3834 - val_top-5-accuracy: 0.7004 - lr: 0.0025\n",
            "Epoch 392/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6148 - accuracy: 0.4553 - top-5-accuracy: 0.7576\n",
            "Epoch 392: ReduceLROnPlateau reducing learning rate to 0.0018984375055879354.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6142 - accuracy: 0.4554 - top-5-accuracy: 0.7579 - val_loss: 2.9897 - val_accuracy: 0.3740 - val_top-5-accuracy: 0.6870 - lr: 0.0019\n",
            "Epoch 393/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5798 - accuracy: 0.4649 - top-5-accuracy: 0.7654 - val_loss: 3.0134 - val_accuracy: 0.3708 - val_top-5-accuracy: 0.6850 - lr: 0.0019\n",
            "Epoch 394/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5753 - accuracy: 0.4683 - top-5-accuracy: 0.7643\n",
            "Epoch 394: ReduceLROnPlateau reducing learning rate to 0.0014238281291909516.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5754 - accuracy: 0.4682 - top-5-accuracy: 0.7644 - val_loss: 2.9738 - val_accuracy: 0.3808 - val_top-5-accuracy: 0.6928 - lr: 0.0014\n",
            "Epoch 395/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5530 - accuracy: 0.4741 - top-5-accuracy: 0.7724 - val_loss: 2.9738 - val_accuracy: 0.3802 - val_top-5-accuracy: 0.7016 - lr: 0.0014\n",
            "Epoch 396/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5511 - accuracy: 0.4731 - top-5-accuracy: 0.7724\n",
            "Epoch 396: ReduceLROnPlateau reducing learning rate to 0.001067871053237468.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5506 - accuracy: 0.4734 - top-5-accuracy: 0.7723 - val_loss: 2.9081 - val_accuracy: 0.3968 - val_top-5-accuracy: 0.7132 - lr: 0.0011\n",
            "Epoch 397/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5303 - accuracy: 0.4787 - top-5-accuracy: 0.7774 - val_loss: 2.8927 - val_accuracy: 0.3992 - val_top-5-accuracy: 0.7140 - lr: 0.0011\n",
            "Epoch 398/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5381 - accuracy: 0.4787 - top-5-accuracy: 0.7743\n",
            "Epoch 398: ReduceLROnPlateau reducing learning rate to 0.0008009032462723553.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5380 - accuracy: 0.4786 - top-5-accuracy: 0.7742 - val_loss: 2.8725 - val_accuracy: 0.4044 - val_top-5-accuracy: 0.7172 - lr: 8.0090e-04\n",
            "Epoch 399/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5135 - accuracy: 0.4843 - top-5-accuracy: 0.7801 - val_loss: 2.8931 - val_accuracy: 0.4026 - val_top-5-accuracy: 0.7138 - lr: 8.0090e-04\n",
            "Epoch 400/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5126 - accuracy: 0.4866 - top-5-accuracy: 0.7817\n",
            "Epoch 400: ReduceLROnPlateau reducing learning rate to 0.0006006774347042665.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5118 - accuracy: 0.4868 - top-5-accuracy: 0.7819 - val_loss: 2.8827 - val_accuracy: 0.4056 - val_top-5-accuracy: 0.7192 - lr: 6.0068e-04\n",
            "Epoch 401/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5033 - accuracy: 0.4882 - top-5-accuracy: 0.7833 - val_loss: 2.8962 - val_accuracy: 0.4060 - val_top-5-accuracy: 0.7166 - lr: 6.0068e-04\n",
            "Epoch 402/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5063 - accuracy: 0.4866 - top-5-accuracy: 0.7849\n",
            "Epoch 402: ReduceLROnPlateau reducing learning rate to 0.0004505080869421363.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5057 - accuracy: 0.4869 - top-5-accuracy: 0.7851 - val_loss: 2.9031 - val_accuracy: 0.3970 - val_top-5-accuracy: 0.7136 - lr: 4.5051e-04\n",
            "Epoch 403/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5019 - accuracy: 0.4884 - top-5-accuracy: 0.7850 - val_loss: 2.9123 - val_accuracy: 0.4006 - val_top-5-accuracy: 0.7144 - lr: 4.5051e-04\n",
            "Epoch 404/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5015 - accuracy: 0.4895 - top-5-accuracy: 0.7845\n",
            "Epoch 404: ReduceLROnPlateau reducing learning rate to 0.0003378810652066022.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5007 - accuracy: 0.4897 - top-5-accuracy: 0.7847 - val_loss: 2.8795 - val_accuracy: 0.4014 - val_top-5-accuracy: 0.7208 - lr: 3.3788e-04\n",
            "Epoch 405/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4950 - accuracy: 0.4905 - top-5-accuracy: 0.7851 - val_loss: 2.9096 - val_accuracy: 0.3954 - val_top-5-accuracy: 0.7174 - lr: 3.3788e-04\n",
            "Epoch 406/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4863 - accuracy: 0.4952 - top-5-accuracy: 0.7874 - val_loss: 2.8853 - val_accuracy: 0.4038 - val_top-5-accuracy: 0.7130 - lr: 3.3788e-04\n",
            "Epoch 407/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4968 - accuracy: 0.4892 - top-5-accuracy: 0.7850 - val_loss: 2.8844 - val_accuracy: 0.4034 - val_top-5-accuracy: 0.7190 - lr: 3.3788e-04\n",
            "Epoch 408/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4936 - accuracy: 0.4918 - top-5-accuracy: 0.7877\n",
            "Epoch 408: ReduceLROnPlateau reducing learning rate to 0.00025341079890495166.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4930 - accuracy: 0.4919 - top-5-accuracy: 0.7878 - val_loss: 2.8983 - val_accuracy: 0.4008 - val_top-5-accuracy: 0.7160 - lr: 2.5341e-04\n",
            "Epoch 409/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4839 - accuracy: 0.4948 - top-5-accuracy: 0.7879 - val_loss: 2.9014 - val_accuracy: 0.4024 - val_top-5-accuracy: 0.7144 - lr: 2.5341e-04\n",
            "Epoch 410/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4887 - accuracy: 0.4942 - top-5-accuracy: 0.7865 - val_loss: 2.8799 - val_accuracy: 0.4082 - val_top-5-accuracy: 0.7188 - lr: 2.5341e-04\n",
            "Epoch 411/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4783 - accuracy: 0.4976 - top-5-accuracy: 0.7904 - val_loss: 2.9015 - val_accuracy: 0.4010 - val_top-5-accuracy: 0.7140 - lr: 2.5341e-04\n",
            "Epoch 412/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4839 - accuracy: 0.4960 - top-5-accuracy: 0.7880 - val_loss: 2.9044 - val_accuracy: 0.4024 - val_top-5-accuracy: 0.7136 - lr: 2.5341e-04\n",
            "Epoch 413/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4759 - accuracy: 0.4967 - top-5-accuracy: 0.7900 - val_loss: 2.8847 - val_accuracy: 0.4060 - val_top-5-accuracy: 0.7202 - lr: 2.5341e-04\n",
            "Epoch 414/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4827 - accuracy: 0.4946 - top-5-accuracy: 0.7895 - val_loss: 2.8864 - val_accuracy: 0.4074 - val_top-5-accuracy: 0.7182 - lr: 2.5341e-04\n",
            "Epoch 415/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4800 - accuracy: 0.4951 - top-5-accuracy: 0.7898\n",
            "Epoch 415: ReduceLROnPlateau reducing learning rate to 0.00019005810463568196.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4806 - accuracy: 0.4948 - top-5-accuracy: 0.7898 - val_loss: 2.8792 - val_accuracy: 0.4110 - val_top-5-accuracy: 0.7198 - lr: 1.9006e-04\n",
            "Epoch 416/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4831 - accuracy: 0.4942 - top-5-accuracy: 0.7889 - val_loss: 2.8891 - val_accuracy: 0.4086 - val_top-5-accuracy: 0.7166 - lr: 1.9006e-04\n",
            "Epoch 417/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4784 - accuracy: 0.4970 - top-5-accuracy: 0.7887\n",
            "Epoch 417: ReduceLROnPlateau reducing learning rate to 0.00014254358393372968.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4787 - accuracy: 0.4969 - top-5-accuracy: 0.7887 - val_loss: 2.8865 - val_accuracy: 0.4064 - val_top-5-accuracy: 0.7152 - lr: 1.4254e-04\n",
            "Epoch 418/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4689 - accuracy: 0.4984 - top-5-accuracy: 0.7916 - val_loss: 2.8834 - val_accuracy: 0.4090 - val_top-5-accuracy: 0.7182 - lr: 1.4254e-04\n",
            "Epoch 419/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4785 - accuracy: 0.4960 - top-5-accuracy: 0.7894 - val_loss: 2.8942 - val_accuracy: 0.4034 - val_top-5-accuracy: 0.7144 - lr: 1.4254e-04\n",
            "Epoch 420/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4690 - accuracy: 0.4976 - top-5-accuracy: 0.7911\n",
            "Epoch 420: ReduceLROnPlateau reducing learning rate to 0.00010690768249332905.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4693 - accuracy: 0.4975 - top-5-accuracy: 0.7912 - val_loss: 2.8898 - val_accuracy: 0.4054 - val_top-5-accuracy: 0.7172 - lr: 1.0691e-04\n",
            "Epoch 421/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4665 - accuracy: 0.4998 - top-5-accuracy: 0.7937 - val_loss: 2.8794 - val_accuracy: 0.4096 - val_top-5-accuracy: 0.7200 - lr: 1.0691e-04\n",
            "Epoch 422/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4668 - accuracy: 0.5006 - top-5-accuracy: 0.7922 - val_loss: 2.8903 - val_accuracy: 0.4054 - val_top-5-accuracy: 0.7160 - lr: 1.0691e-04\n",
            "Epoch 423/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4779 - accuracy: 0.4988 - top-5-accuracy: 0.7912\n",
            "Epoch 423: ReduceLROnPlateau reducing learning rate to 8.018076186999679e-05.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4769 - accuracy: 0.4992 - top-5-accuracy: 0.7913 - val_loss: 2.8845 - val_accuracy: 0.4080 - val_top-5-accuracy: 0.7180 - lr: 8.0181e-05\n",
            "Epoch 424/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7562 - accuracy: 0.4120 - top-5-accuracy: 0.7216 - val_loss: 3.0974 - val_accuracy: 0.3468 - val_top-5-accuracy: 0.6562 - lr: 0.0060\n",
            "Epoch 425/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7585 - accuracy: 0.4103 - top-5-accuracy: 0.7218\n",
            "Epoch 425: ReduceLROnPlateau reducing learning rate to 0.004500000039115548.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7579 - accuracy: 0.4105 - top-5-accuracy: 0.7219 - val_loss: 3.0611 - val_accuracy: 0.3528 - val_top-5-accuracy: 0.6622 - lr: 0.0045\n",
            "Epoch 426/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6896 - accuracy: 0.4323 - top-5-accuracy: 0.7386 - val_loss: 3.0564 - val_accuracy: 0.3510 - val_top-5-accuracy: 0.6824 - lr: 0.0045\n",
            "Epoch 427/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6705 - accuracy: 0.4376 - top-5-accuracy: 0.7438\n",
            "Epoch 427: ReduceLROnPlateau reducing learning rate to 0.0033749998547136784.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6707 - accuracy: 0.4377 - top-5-accuracy: 0.7438 - val_loss: 3.0532 - val_accuracy: 0.3688 - val_top-5-accuracy: 0.6790 - lr: 0.0034\n",
            "Epoch 428/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6322 - accuracy: 0.4480 - top-5-accuracy: 0.7519 - val_loss: 2.9987 - val_accuracy: 0.3832 - val_top-5-accuracy: 0.6926 - lr: 0.0034\n",
            "Epoch 429/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6327 - accuracy: 0.4506 - top-5-accuracy: 0.7513\n",
            "Epoch 429: ReduceLROnPlateau reducing learning rate to 0.0025312498910352588.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6331 - accuracy: 0.4504 - top-5-accuracy: 0.7512 - val_loss: 2.9439 - val_accuracy: 0.3826 - val_top-5-accuracy: 0.7064 - lr: 0.0025\n",
            "Epoch 430/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6103 - accuracy: 0.4547 - top-5-accuracy: 0.7558 - val_loss: 2.9849 - val_accuracy: 0.3766 - val_top-5-accuracy: 0.6952 - lr: 0.0025\n",
            "Epoch 431/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5802 - accuracy: 0.4648 - top-5-accuracy: 0.7635\n",
            "Epoch 431: ReduceLROnPlateau reducing learning rate to 0.0018984375055879354.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5796 - accuracy: 0.4648 - top-5-accuracy: 0.7637 - val_loss: 2.9573 - val_accuracy: 0.3928 - val_top-5-accuracy: 0.6994 - lr: 0.0019\n",
            "Epoch 432/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5717 - accuracy: 0.4697 - top-5-accuracy: 0.7671 - val_loss: 2.9489 - val_accuracy: 0.3878 - val_top-5-accuracy: 0.7012 - lr: 0.0019\n",
            "Epoch 433/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5620 - accuracy: 0.4713 - top-5-accuracy: 0.7697\n",
            "Epoch 433: ReduceLROnPlateau reducing learning rate to 0.0014238281291909516.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5627 - accuracy: 0.4710 - top-5-accuracy: 0.7696 - val_loss: 2.8976 - val_accuracy: 0.3996 - val_top-5-accuracy: 0.7148 - lr: 0.0014\n",
            "Epoch 434/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5540 - accuracy: 0.4703 - top-5-accuracy: 0.7716 - val_loss: 2.8894 - val_accuracy: 0.4006 - val_top-5-accuracy: 0.7132 - lr: 0.0014\n",
            "Epoch 435/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5375 - accuracy: 0.4771 - top-5-accuracy: 0.7767\n",
            "Epoch 435: ReduceLROnPlateau reducing learning rate to 0.001067871053237468.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5369 - accuracy: 0.4773 - top-5-accuracy: 0.7767 - val_loss: 2.8750 - val_accuracy: 0.4072 - val_top-5-accuracy: 0.7168 - lr: 0.0011\n",
            "Epoch 436/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5211 - accuracy: 0.4844 - top-5-accuracy: 0.7778 - val_loss: 2.9165 - val_accuracy: 0.4028 - val_top-5-accuracy: 0.7098 - lr: 0.0011\n",
            "Epoch 437/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5137 - accuracy: 0.4855 - top-5-accuracy: 0.7826\n",
            "Epoch 437: ReduceLROnPlateau reducing learning rate to 0.0008009032462723553.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5128 - accuracy: 0.4857 - top-5-accuracy: 0.7828 - val_loss: 2.8817 - val_accuracy: 0.4040 - val_top-5-accuracy: 0.7164 - lr: 8.0090e-04\n",
            "Epoch 438/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5096 - accuracy: 0.4872 - top-5-accuracy: 0.7841 - val_loss: 2.9041 - val_accuracy: 0.4056 - val_top-5-accuracy: 0.7140 - lr: 8.0090e-04\n",
            "Epoch 439/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5033 - accuracy: 0.4877 - top-5-accuracy: 0.7835\n",
            "Epoch 439: ReduceLROnPlateau reducing learning rate to 0.0006006774347042665.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5033 - accuracy: 0.4877 - top-5-accuracy: 0.7836 - val_loss: 2.8806 - val_accuracy: 0.4048 - val_top-5-accuracy: 0.7220 - lr: 6.0068e-04\n",
            "Epoch 440/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4943 - accuracy: 0.4906 - top-5-accuracy: 0.7866 - val_loss: 2.9313 - val_accuracy: 0.4034 - val_top-5-accuracy: 0.7058 - lr: 6.0068e-04\n",
            "Epoch 441/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4932 - accuracy: 0.4914 - top-5-accuracy: 0.7858\n",
            "Epoch 441: ReduceLROnPlateau reducing learning rate to 0.0004505080869421363.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4935 - accuracy: 0.4912 - top-5-accuracy: 0.7858 - val_loss: 2.8976 - val_accuracy: 0.4076 - val_top-5-accuracy: 0.7130 - lr: 4.5051e-04\n",
            "Epoch 442/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4851 - accuracy: 0.4971 - top-5-accuracy: 0.7880 - val_loss: 2.8876 - val_accuracy: 0.4120 - val_top-5-accuracy: 0.7150 - lr: 4.5051e-04\n",
            "Epoch 443/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4865 - accuracy: 0.4935 - top-5-accuracy: 0.7872\n",
            "Epoch 443: ReduceLROnPlateau reducing learning rate to 0.0003378810652066022.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4867 - accuracy: 0.4934 - top-5-accuracy: 0.7873 - val_loss: 2.8772 - val_accuracy: 0.4126 - val_top-5-accuracy: 0.7162 - lr: 3.3788e-04\n",
            "Epoch 444/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4662 - accuracy: 0.5000 - top-5-accuracy: 0.7941 - val_loss: 2.8964 - val_accuracy: 0.4120 - val_top-5-accuracy: 0.7134 - lr: 3.3788e-04\n",
            "Epoch 445/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4709 - accuracy: 0.4968 - top-5-accuracy: 0.7916 - val_loss: 2.8867 - val_accuracy: 0.4064 - val_top-5-accuracy: 0.7146 - lr: 3.3788e-04\n",
            "Epoch 446/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4767 - accuracy: 0.4955 - top-5-accuracy: 0.7906\n",
            "Epoch 446: ReduceLROnPlateau reducing learning rate to 0.00025341079890495166.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4769 - accuracy: 0.4953 - top-5-accuracy: 0.7906 - val_loss: 2.8749 - val_accuracy: 0.4134 - val_top-5-accuracy: 0.7178 - lr: 2.5341e-04\n",
            "Epoch 447/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4660 - accuracy: 0.5000 - top-5-accuracy: 0.7924 - val_loss: 2.8701 - val_accuracy: 0.4182 - val_top-5-accuracy: 0.7202 - lr: 2.5341e-04\n",
            "Epoch 448/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4762 - accuracy: 0.4959 - top-5-accuracy: 0.7910 - val_loss: 2.8486 - val_accuracy: 0.4224 - val_top-5-accuracy: 0.7236 - lr: 2.5341e-04\n",
            "Epoch 449/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4679 - accuracy: 0.5017 - top-5-accuracy: 0.7923\n",
            "Epoch 449: ReduceLROnPlateau reducing learning rate to 0.00019005810463568196.\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 2.4676 - accuracy: 0.5018 - top-5-accuracy: 0.7923 - val_loss: 2.8557 - val_accuracy: 0.4142 - val_top-5-accuracy: 0.7256 - lr: 1.9006e-04\n",
            "Epoch 450/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 2.4704 - accuracy: 0.5002 - top-5-accuracy: 0.7909 - val_loss: 2.8475 - val_accuracy: 0.4176 - val_top-5-accuracy: 0.7218 - lr: 1.9006e-04\n",
            "Epoch 451/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4579 - accuracy: 0.5014 - top-5-accuracy: 0.7944 - val_loss: 2.8652 - val_accuracy: 0.4196 - val_top-5-accuracy: 0.7194 - lr: 1.9006e-04\n",
            "Epoch 452/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4636 - accuracy: 0.5013 - top-5-accuracy: 0.7942 - val_loss: 2.8691 - val_accuracy: 0.4118 - val_top-5-accuracy: 0.7198 - lr: 1.9006e-04\n",
            "Epoch 453/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4696 - accuracy: 0.4986 - top-5-accuracy: 0.7920\n",
            "Epoch 453: ReduceLROnPlateau reducing learning rate to 0.00014254358393372968.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4700 - accuracy: 0.4986 - top-5-accuracy: 0.7919 - val_loss: 2.8548 - val_accuracy: 0.4176 - val_top-5-accuracy: 0.7212 - lr: 1.4254e-04\n",
            "Epoch 454/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4616 - accuracy: 0.5016 - top-5-accuracy: 0.7940 - val_loss: 2.8840 - val_accuracy: 0.4132 - val_top-5-accuracy: 0.7150 - lr: 1.4254e-04\n",
            "Epoch 455/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4573 - accuracy: 0.5023 - top-5-accuracy: 0.7933 - val_loss: 2.8552 - val_accuracy: 0.4196 - val_top-5-accuracy: 0.7202 - lr: 1.4254e-04\n",
            "Epoch 456/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4612 - accuracy: 0.5014 - top-5-accuracy: 0.7933 - val_loss: 2.8494 - val_accuracy: 0.4176 - val_top-5-accuracy: 0.7210 - lr: 1.4254e-04\n",
            "Epoch 457/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4662 - accuracy: 0.4999 - top-5-accuracy: 0.7916\n",
            "Epoch 457: ReduceLROnPlateau reducing learning rate to 0.00010690768249332905.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4662 - accuracy: 0.5000 - top-5-accuracy: 0.7916 - val_loss: 2.8484 - val_accuracy: 0.4188 - val_top-5-accuracy: 0.7220 - lr: 1.0691e-04\n",
            "Epoch 458/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4579 - accuracy: 0.5022 - top-5-accuracy: 0.7950 - val_loss: 2.8453 - val_accuracy: 0.4186 - val_top-5-accuracy: 0.7228 - lr: 1.0691e-04\n",
            "Epoch 459/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4564 - accuracy: 0.5038 - top-5-accuracy: 0.7952 - val_loss: 2.8433 - val_accuracy: 0.4142 - val_top-5-accuracy: 0.7250 - lr: 1.0691e-04\n",
            "Epoch 460/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4592 - accuracy: 0.5001 - top-5-accuracy: 0.7943 - val_loss: 2.8527 - val_accuracy: 0.4168 - val_top-5-accuracy: 0.7196 - lr: 1.0691e-04\n",
            "Epoch 461/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4490 - accuracy: 0.5074 - top-5-accuracy: 0.7980 - val_loss: 2.8462 - val_accuracy: 0.4172 - val_top-5-accuracy: 0.7200 - lr: 1.0691e-04\n",
            "Epoch 462/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4547 - accuracy: 0.5008 - top-5-accuracy: 0.7973 - val_loss: 2.8564 - val_accuracy: 0.4162 - val_top-5-accuracy: 0.7174 - lr: 1.0691e-04\n",
            "Epoch 463/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4582 - accuracy: 0.5033 - top-5-accuracy: 0.7944\n",
            "Epoch 463: ReduceLROnPlateau reducing learning rate to 8.018076186999679e-05.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4583 - accuracy: 0.5032 - top-5-accuracy: 0.7944 - val_loss: 2.8527 - val_accuracy: 0.4174 - val_top-5-accuracy: 0.7212 - lr: 8.0181e-05\n",
            "Epoch 464/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7632 - accuracy: 0.4113 - top-5-accuracy: 0.7206 - val_loss: 3.0724 - val_accuracy: 0.3640 - val_top-5-accuracy: 0.6682 - lr: 0.0060\n",
            "Epoch 465/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7142 - accuracy: 0.4227 - top-5-accuracy: 0.7324\n",
            "Epoch 465: ReduceLROnPlateau reducing learning rate to 0.004500000039115548.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.7151 - accuracy: 0.4225 - top-5-accuracy: 0.7322 - val_loss: 3.2664 - val_accuracy: 0.3178 - val_top-5-accuracy: 0.6312 - lr: 0.0045\n",
            "Epoch 466/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6933 - accuracy: 0.4308 - top-5-accuracy: 0.7383 - val_loss: 2.9800 - val_accuracy: 0.3760 - val_top-5-accuracy: 0.6910 - lr: 0.0045\n",
            "Epoch 467/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6670 - accuracy: 0.4389 - top-5-accuracy: 0.7422\n",
            "Epoch 467: ReduceLROnPlateau reducing learning rate to 0.0033749998547136784.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6673 - accuracy: 0.4388 - top-5-accuracy: 0.7422 - val_loss: 3.0042 - val_accuracy: 0.3744 - val_top-5-accuracy: 0.6832 - lr: 0.0034\n",
            "Epoch 468/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.6277 - accuracy: 0.4513 - top-5-accuracy: 0.7533 - val_loss: 2.9865 - val_accuracy: 0.3860 - val_top-5-accuracy: 0.6894 - lr: 0.0034\n",
            "Epoch 469/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.6096 - accuracy: 0.4569 - top-5-accuracy: 0.7582\n",
            "Epoch 469: ReduceLROnPlateau reducing learning rate to 0.0025312498910352588.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6096 - accuracy: 0.4569 - top-5-accuracy: 0.7583 - val_loss: 2.9187 - val_accuracy: 0.3904 - val_top-5-accuracy: 0.7014 - lr: 0.0025\n",
            "Epoch 470/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5953 - accuracy: 0.4617 - top-5-accuracy: 0.7603 - val_loss: 2.9277 - val_accuracy: 0.3956 - val_top-5-accuracy: 0.7058 - lr: 0.0025\n",
            "Epoch 471/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5778 - accuracy: 0.4659 - top-5-accuracy: 0.7652\n",
            "Epoch 471: ReduceLROnPlateau reducing learning rate to 0.0018984375055879354.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5777 - accuracy: 0.4660 - top-5-accuracy: 0.7652 - val_loss: 2.9893 - val_accuracy: 0.3898 - val_top-5-accuracy: 0.6966 - lr: 0.0019\n",
            "Epoch 472/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5490 - accuracy: 0.4749 - top-5-accuracy: 0.7737 - val_loss: 2.9226 - val_accuracy: 0.3974 - val_top-5-accuracy: 0.7100 - lr: 0.0019\n",
            "Epoch 473/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5494 - accuracy: 0.4737 - top-5-accuracy: 0.7724\n",
            "Epoch 473: ReduceLROnPlateau reducing learning rate to 0.0014238281291909516.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5491 - accuracy: 0.4741 - top-5-accuracy: 0.7725 - val_loss: 2.9676 - val_accuracy: 0.3870 - val_top-5-accuracy: 0.6928 - lr: 0.0014\n",
            "Epoch 474/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5314 - accuracy: 0.4783 - top-5-accuracy: 0.7777 - val_loss: 2.8679 - val_accuracy: 0.4160 - val_top-5-accuracy: 0.7250 - lr: 0.0014\n",
            "Epoch 475/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5248 - accuracy: 0.4810 - top-5-accuracy: 0.7805\n",
            "Epoch 475: ReduceLROnPlateau reducing learning rate to 0.001067871053237468.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5243 - accuracy: 0.4813 - top-5-accuracy: 0.7806 - val_loss: 2.9554 - val_accuracy: 0.3944 - val_top-5-accuracy: 0.7026 - lr: 0.0011\n",
            "Epoch 476/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5016 - accuracy: 0.4887 - top-5-accuracy: 0.7823 - val_loss: 2.8865 - val_accuracy: 0.4076 - val_top-5-accuracy: 0.7180 - lr: 0.0011\n",
            "Epoch 477/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.5109 - accuracy: 0.4861 - top-5-accuracy: 0.7810\n",
            "Epoch 477: ReduceLROnPlateau reducing learning rate to 0.0008009032462723553.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.5103 - accuracy: 0.4865 - top-5-accuracy: 0.7812 - val_loss: 2.8782 - val_accuracy: 0.4164 - val_top-5-accuracy: 0.7196 - lr: 8.0090e-04\n",
            "Epoch 478/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.5011 - accuracy: 0.4877 - top-5-accuracy: 0.7843 - val_loss: 2.9014 - val_accuracy: 0.4112 - val_top-5-accuracy: 0.7156 - lr: 8.0090e-04\n",
            "Epoch 479/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4898 - accuracy: 0.4906 - top-5-accuracy: 0.7856\n",
            "Epoch 479: ReduceLROnPlateau reducing learning rate to 0.0006006774347042665.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4894 - accuracy: 0.4907 - top-5-accuracy: 0.7858 - val_loss: 2.8545 - val_accuracy: 0.4200 - val_top-5-accuracy: 0.7208 - lr: 6.0068e-04\n",
            "Epoch 480/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4827 - accuracy: 0.4950 - top-5-accuracy: 0.7878 - val_loss: 2.8420 - val_accuracy: 0.4170 - val_top-5-accuracy: 0.7206 - lr: 6.0068e-04\n",
            "Epoch 481/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4757 - accuracy: 0.4960 - top-5-accuracy: 0.7893\n",
            "Epoch 481: ReduceLROnPlateau reducing learning rate to 0.0004505080869421363.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4763 - accuracy: 0.4959 - top-5-accuracy: 0.7891 - val_loss: 2.8561 - val_accuracy: 0.4188 - val_top-5-accuracy: 0.7244 - lr: 4.5051e-04\n",
            "Epoch 482/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4655 - accuracy: 0.5012 - top-5-accuracy: 0.7940 - val_loss: 2.8482 - val_accuracy: 0.4240 - val_top-5-accuracy: 0.7252 - lr: 4.5051e-04\n",
            "Epoch 483/500\n",
            "174/176 [============================>.] - ETA: 0s - loss: 2.4756 - accuracy: 0.4955 - top-5-accuracy: 0.7896\n",
            "Epoch 483: ReduceLROnPlateau reducing learning rate to 0.0003378810652066022.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4755 - accuracy: 0.4953 - top-5-accuracy: 0.7895 - val_loss: 2.8505 - val_accuracy: 0.4230 - val_top-5-accuracy: 0.7242 - lr: 3.3788e-04\n",
            "Epoch 484/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4652 - accuracy: 0.4995 - top-5-accuracy: 0.7924 - val_loss: 2.8667 - val_accuracy: 0.4170 - val_top-5-accuracy: 0.7198 - lr: 3.3788e-04\n",
            "Epoch 485/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4627 - accuracy: 0.5032 - top-5-accuracy: 0.7924\n",
            "Epoch 485: ReduceLROnPlateau reducing learning rate to 0.00025341079890495166.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4623 - accuracy: 0.5033 - top-5-accuracy: 0.7925 - val_loss: 2.8386 - val_accuracy: 0.4254 - val_top-5-accuracy: 0.7292 - lr: 2.5341e-04\n",
            "Epoch 486/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4611 - accuracy: 0.5002 - top-5-accuracy: 0.7959 - val_loss: 2.8564 - val_accuracy: 0.4216 - val_top-5-accuracy: 0.7212 - lr: 2.5341e-04\n",
            "Epoch 487/500\n",
            "174/176 [============================>.] - ETA: 0s - loss: 2.4594 - accuracy: 0.4996 - top-5-accuracy: 0.7948\n",
            "Epoch 487: ReduceLROnPlateau reducing learning rate to 0.00019005810463568196.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4601 - accuracy: 0.4994 - top-5-accuracy: 0.7947 - val_loss: 2.8553 - val_accuracy: 0.4200 - val_top-5-accuracy: 0.7242 - lr: 1.9006e-04\n",
            "Epoch 488/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4647 - accuracy: 0.4982 - top-5-accuracy: 0.7920 - val_loss: 2.8459 - val_accuracy: 0.4208 - val_top-5-accuracy: 0.7256 - lr: 1.9006e-04\n",
            "Epoch 489/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4459 - accuracy: 0.5061 - top-5-accuracy: 0.7972 - val_loss: 2.8559 - val_accuracy: 0.4234 - val_top-5-accuracy: 0.7232 - lr: 1.9006e-04\n",
            "Epoch 490/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4548 - accuracy: 0.5036 - top-5-accuracy: 0.7975 - val_loss: 2.8492 - val_accuracy: 0.4232 - val_top-5-accuracy: 0.7296 - lr: 1.9006e-04\n",
            "Epoch 491/500\n",
            "174/176 [============================>.] - ETA: 0s - loss: 2.4542 - accuracy: 0.5051 - top-5-accuracy: 0.7956\n",
            "Epoch 491: ReduceLROnPlateau reducing learning rate to 0.00014254358393372968.\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.4535 - accuracy: 0.5052 - top-5-accuracy: 0.7958 - val_loss: 2.8357 - val_accuracy: 0.4234 - val_top-5-accuracy: 0.7276 - lr: 1.4254e-04\n",
            "Epoch 492/500\n",
            "176/176 [==============================] - 4s 25ms/step - loss: 2.4517 - accuracy: 0.5049 - top-5-accuracy: 0.7959 - val_loss: 2.8539 - val_accuracy: 0.4190 - val_top-5-accuracy: 0.7256 - lr: 1.4254e-04\n",
            "Epoch 493/500\n",
            "176/176 [==============================] - 5s 27ms/step - loss: 2.4340 - accuracy: 0.5095 - top-5-accuracy: 0.7990 - val_loss: 2.8432 - val_accuracy: 0.4250 - val_top-5-accuracy: 0.7288 - lr: 1.4254e-04\n",
            "Epoch 494/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4480 - accuracy: 0.5052 - top-5-accuracy: 0.7970 - val_loss: 2.8411 - val_accuracy: 0.4242 - val_top-5-accuracy: 0.7290 - lr: 1.4254e-04\n",
            "Epoch 495/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4472 - accuracy: 0.5067 - top-5-accuracy: 0.7956\n",
            "Epoch 495: ReduceLROnPlateau reducing learning rate to 0.00010690768249332905.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4468 - accuracy: 0.5068 - top-5-accuracy: 0.7958 - val_loss: 2.8434 - val_accuracy: 0.4240 - val_top-5-accuracy: 0.7292 - lr: 1.0691e-04\n",
            "Epoch 496/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4457 - accuracy: 0.5048 - top-5-accuracy: 0.7987 - val_loss: 2.8389 - val_accuracy: 0.4208 - val_top-5-accuracy: 0.7284 - lr: 1.0691e-04\n",
            "Epoch 497/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.4487 - accuracy: 0.5040 - top-5-accuracy: 0.7992\n",
            "Epoch 497: ReduceLROnPlateau reducing learning rate to 8.018076186999679e-05.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.4481 - accuracy: 0.5043 - top-5-accuracy: 0.7993 - val_loss: 2.8376 - val_accuracy: 0.4244 - val_top-5-accuracy: 0.7284 - lr: 8.0181e-05\n",
            "Epoch 498/500\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7526 - accuracy: 0.4148 - top-5-accuracy: 0.7242 - val_loss: 3.0015 - val_accuracy: 0.3740 - val_top-5-accuracy: 0.6760 - lr: 0.0060\n",
            "Epoch 499/500\n",
            "175/176 [============================>.] - ETA: 0s - loss: 2.7344 - accuracy: 0.4191 - top-5-accuracy: 0.7265\n",
            "Epoch 499: ReduceLROnPlateau reducing learning rate to 0.004500000039115548.\n",
            "176/176 [==============================] - 4s 23ms/step - loss: 2.7349 - accuracy: 0.4191 - top-5-accuracy: 0.7264 - val_loss: 3.3713 - val_accuracy: 0.3056 - val_top-5-accuracy: 0.6084 - lr: 0.0045\n",
            "Epoch 500/500\n",
            "176/176 [==============================] - 4s 24ms/step - loss: 2.6578 - accuracy: 0.4394 - top-5-accuracy: 0.7457 - val_loss: 3.1098 - val_accuracy: 0.3514 - val_top-5-accuracy: 0.6692 - lr: 0.0045\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.8298 - accuracy: 0.4315 - top-5-accuracy: 0.7286\n",
            "Test accuracy: 43.15%\n",
            "Test top 5 accuracy: 72.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Illustrazione risultati di addestramento se lo avessi lasciato addestrare piu epoche sarebbe migliorato ancora ho implementato l'aumento del learning rate perche intorno alla loss pari a 0.26 c'era un minimo locale che sono riuscito a fargli superare con successo grazie a questa tecnica"
      ],
      "metadata": {
        "id": "KMxeXMSmqH12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,4))\n",
        "\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax1.plot(history.history[\"loss\"], label=\"addestramento\")\n",
        "ax1.plot(history.history[\"val_loss\"], label=\"validazione\")\n",
        "ax1.set_xlabel(\"Epoche\")\n",
        "ax1.set_ylabel(\"Errore\")\n",
        "ax1.set_title(\"Errore durante l'addestramento\", fontsize=14)\n",
        "ax1.legend()\n",
        "ax1.grid()\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history.history[\"top-5-accuracy\"], label=\"addestramento\")\n",
        "ax2.plot(history.history[\"val_top-5-accuracy\"], label=\"validazione\")\n",
        "ax2.set_xlabel(\"Epoche\")\n",
        "ax2.set_ylabel(\"Accuratezza\")\n",
        "ax2.set_title(\"Accuratezza durante l'addestramento\", fontsize=14)\n",
        "ax2.legend()\n",
        "ax2.grid()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W6di2NeNVVl3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "6c5a5cf9-f303-4b85-d560-08d6d4f8c6a8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Oo-Q1NLGSR8P"
      }
    }
  ]
}